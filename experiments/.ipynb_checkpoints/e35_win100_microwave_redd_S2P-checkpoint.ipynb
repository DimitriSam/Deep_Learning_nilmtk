{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Gz9jitiMmFkE",
    "outputId": "39a18170-237d-4c47-9a40-697b3f38a7a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nModel: DreNet \\nAplpiance: fridge\\nData: Redd\\n\\nMethod:S2P\\nNormalization: data/max\\nbatch_size: 128,\\nwindow_size: 1\\nshuffle: True\\n\\nnum epochs=50\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Model: DreNet \n",
    "Aplpiance: microwave\n",
    "Data: Redd\n",
    "\n",
    "Method:S2P\n",
    "Normalization: no norm\n",
    "batch_size: 128,\n",
    "window_size: 100\n",
    "shuffle: True\n",
    "\n",
    "num epochs=50\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 126
    },
    "colab_type": "code",
    "id": "ObzzZOy1zAzo",
    "outputId": "05a83aa5-db30-48e0-e741-66e9c7ebe691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import sys\n",
    "sys.path.insert(0,'drive/My Drive/Dissertation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "amHn1qgwzEI2",
    "outputId": "a3ba967c-5598-4f45-987f-b6d068a9a524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/nilmtk/nilmtk.git\n",
      "  Cloning git://github.com/nilmtk/nilmtk.git to /tmp/pip-req-build-nsydmraw\n",
      "  Running command git clone -q git://github.com/nilmtk/nilmtk.git /tmp/pip-req-build-nsydmraw\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (0.16.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (1.12.0)\n",
      "Collecting psycopg2-binary (from nilmtk==0.3.0.dev0+git.511e8e8)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/35/75c9c2d9cfc073ab6c42b2d8e91ff58c9b99f4ed7ed56b36647642e6080e/psycopg2_binary-2.8.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 37.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (0.24.2)\n",
      "Collecting networkx==2.1 (from nilmtk==0.3.0.dev0+git.511e8e8)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/42/f951cc6838a4dff6ce57211c4d7f8444809ccbe2134179950301e5c4c83c/networkx-2.1.zip (1.6MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6MB 38.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (1.3.0)\n",
      "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (3.4.4)\n",
      "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (0.21.2)\n",
      "Collecting hmmlearn>=0.2.1 (from nilmtk==0.3.0.dev0+git.511e8e8)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/c5/91b43156b193d180ed94069269bcf88d3c7c6e54514a8482050fa9995e10/hmmlearn-0.2.2.tar.gz (146kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 44.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (3.13)\n",
      "Requirement already satisfied: matplotlib>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (3.0.3)\n",
      "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (1.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->nilmtk==0.3.0.dev0+git.511e8e8) (2.5.3)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->nilmtk==0.3.0.dev0+git.511e8e8) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->nilmtk==0.3.0.dev0+git.511e8e8) (1.16.4)\n",
      "Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from networkx==2.1->nilmtk==0.3.0.dev0+git.511e8e8) (4.4.0)\n",
      "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->nilmtk==0.3.0.dev0+git.511e8e8) (2.6.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.2->nilmtk==0.3.0.dev0+git.511e8e8) (0.13.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.0->nilmtk==0.3.0.dev0+git.511e8e8) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.0->nilmtk==0.3.0.dev0+git.511e8e8) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.0->nilmtk==0.3.0.dev0+git.511e8e8) (2.4.0)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (6.0.0)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (5.5.0)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (5.2.2)\n",
      "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.5.1)\n",
      "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.6.1)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (7.4.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.0->nilmtk==0.3.0.dev0+git.511e8e8) (41.0.1)\n",
      "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (5.5.0)\n",
      "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
      "\u001b[K     |████████████████████████████████| 337kB 46.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (5.2.4)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (2.1.3)\n",
      "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (2.10.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (1.4.2)\n",
      "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.3.2)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.4.2)\n",
      "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.4.0)\n",
      "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.5.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.6.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (3.1.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.2.0)\n",
      "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.8.2)\n",
      "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.5.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (3.4.2)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.8.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.7.5)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.1.7)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (17.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (1.1.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (2.6.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.5.1)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.6.0)\n",
      "Building wheels for collected packages: nilmtk, networkx, hmmlearn\n",
      "  Building wheel for nilmtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-0ce5xeg_/wheels/71/84/2f/eca0fb8014a0fe59881ab1a3e3374f4108211de4c7c3081e8d\n",
      "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/44/c0/34/6f98693a554301bdb405f8d65d95bbcd3e50180cbfdd98a94e\n",
      "  Building wheel for hmmlearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/2c/b6/0e/63a865a30e21e01d04f417d8995fbfb793d6bd464707efc546\n",
      "Successfully built nilmtk networkx hmmlearn\n",
      "\u001b[31mERROR: ipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: psycopg2-binary, networkx, hmmlearn, nilmtk, prompt-toolkit\n",
      "  Found existing installation: networkx 2.3\n",
      "    Uninstalling networkx-2.3:\n",
      "      Successfully uninstalled networkx-2.3\n",
      "  Found existing installation: prompt-toolkit 1.0.16\n",
      "    Uninstalling prompt-toolkit-1.0.16:\n",
      "      Successfully uninstalled prompt-toolkit-1.0.16\n",
      "Successfully installed hmmlearn-0.2.2 networkx-2.1 nilmtk-0.3.0.dev0+git.511e8e8 prompt-toolkit-2.0.9 psycopg2-binary-2.8.3\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "prompt_toolkit"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install git+git://github.com/nilmtk/nilmtk.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "yP1czK5szE76",
    "outputId": "c58161e5-8e90-4b7c-8d19-c4409f350d9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+git://github.com/nilmtk/nilm_metadata.git\n",
      "  Cloning git://github.com/nilmtk/nilm_metadata.git to /tmp/pip-req-build-ln31vpy1\n",
      "  Running command git clone -q git://github.com/nilmtk/nilm_metadata.git /tmp/pip-req-build-ln31vpy1\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from nilm-metadata==0.2.3) (3.13)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nilm-metadata==0.2.3) (1.12.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nilm-metadata==0.2.3) (0.24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->nilm-metadata==0.2.3) (2.5.3)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas->nilm-metadata==0.2.3) (1.16.4)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->nilm-metadata==0.2.3) (2018.9)\n",
      "Building wheels for collected packages: nilm-metadata\n",
      "  Building wheel for nilm-metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-it8ec2id/wheels/75/e0/6d/1ec555a322c151fe20b4c9834753a692203b1f62a66b3ee235\n",
      "Successfully built nilm-metadata\n",
      "Installing collected packages: nilm-metadata\n",
      "Successfully installed nilm-metadata-0.2.3\n"
     ]
    }
   ],
   "source": [
    "pip install git+git://github.com/nilmtk/nilm_metadata.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "colab_type": "code",
    "id": "aLVywoaWzG-s",
    "outputId": "e78b74e9-2f9a-4565-9419-bb5516c612eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==0.24.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/e1/4a63ed31e1b1362d40ce845a5735c717a959bda992669468dae3420af2cd/pandas-0.24.0-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1MB 34.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.0) (2018.9)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.0) (1.16.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.0) (2.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas==0.24.0) (1.12.0)\n",
      "\u001b[31mERROR: nilmtk 0.3.0.dev0+git.511e8e8 has requirement pandas==0.24.2, but you'll have pandas 0.24.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pandas\n",
      "  Found existing installation: pandas 0.24.2\n",
      "    Uninstalling pandas-0.24.2:\n",
      "      Successfully uninstalled pandas-0.24.2\n",
      "Successfully installed pandas-0.24.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "pandas"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install pandas==0.24.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVqjo-MkycMZ"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import time\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset(window_per_house,test_window, filename, meter_label, train_building, test_building, **load_kwargs):\n",
    "    \n",
    "    #Load datasets\n",
    "    train = DataSet(filename)\n",
    "    test = DataSet(filename)\n",
    "\n",
    "    #train.set_window(start=start_train, end=end_train)\n",
    "    test.set_window(*test_window[test_building])\n",
    "\n",
    "    train_mainlist = []\n",
    "    train_meterlist = []\n",
    "    for building_id, building in train.buildings.items():\n",
    "        if building_id in train_building:\n",
    "            train.set_window(*window_per_house[building_id])\n",
    "            y = building.elec[meter_label]\n",
    "            \n",
    "            if filename[-7:] == 'redd.h5':\n",
    "                x = building.elec.mains().all_meters()[0] \n",
    "                \n",
    "            else:\n",
    "                x = building.elec.mains()\n",
    "                \n",
    "            train_mainlist.append(x.power_series_all_data(**load_kwargs))\n",
    "            train_meterlist.append(y.power_series_all_data(**load_kwargs))\n",
    "            \n",
    "\n",
    "    test_meterlist = test.buildings[test_building].elec[meter_label]\n",
    "    \n",
    "    if filename[-7:] == 'redd.h5':\n",
    "        test_mainlist = test.buildings[test_building].elec.mains().all_meters()[0]\n",
    "    else:\n",
    "        test_mainlist = test.buildings[test_building].elec.mains()\n",
    "\n",
    "    assert len(train_mainlist) == len(train_meterlist), \"The number of main and apliances meters must be equal\"\n",
    "\n",
    "    return train_meterlist, train_mainlist, test_meterlist, test_mainlist\n",
    "\n",
    "\n",
    "def data_processing(train_mainlist, train_meterlist, window_size):\n",
    "    '''Data processing\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_mainlist : a list of nilmtk.ElecMeter objects for the aggregate data of each building\n",
    "    train_meterlist : a list of nilmtk.ElecMeter objects for the meter data of each building\n",
    "    '''\n",
    "\n",
    "    # Normalize the data\n",
    "    #train_x = [normalise(data) for data in train_mainlist]\n",
    "    #train_y = [normalise(data) for data in train_meterlist]\n",
    "    \n",
    "    train_x = [data for data in train_mainlist]\n",
    "    train_y = [data for data in train_meterlist]\n",
    "\n",
    "    # replca NaN values and\n",
    "    for i in range(len(train_x)):\n",
    "        train_x[i].fillna(0, inplace=True)\n",
    "        train_y[i].fillna(0, inplace=True)\n",
    "        ix = train_x[i].index.intersection(train_y[i].index)\n",
    "\n",
    "        train_x[i] = train_x[i][ix].values\n",
    "        train_y[i] = train_y[i][ix].values\n",
    "\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalise(data):\n",
    "    \"\"\"\n",
    "    Perform the normalisation (x-min(x))/(max(x)-min(x)).\n",
    "    --------------------------------------\n",
    "    :arg\n",
    "    data: data that needs to be transformed\n",
    "    mean: mean value of data\n",
    "    max_v: max value of data\n",
    "    :return\n",
    "    The normalized data\n",
    "    \"\"\"\n",
    "#     std =np.std(data)\n",
    "#     mean = data.mean()\n",
    "#     max_v = data.max()\n",
    "\n",
    "    return data/4505.783 #remember to try this normalization as well\n",
    "    #return (data - mean) / (max_v-mean)\n",
    "\n",
    "\n",
    "def inversenormalise(data):\n",
    "    \"\"\"\n",
    "    Perform the in-normalisation data*(max(x)-min(x))+min(x).\n",
    "    ------------------------------------------------\n",
    "    :arg\n",
    "    data: data that needs to be inverse-transformed\n",
    "    mean: mean value of data\n",
    "    max_v: max value of data\n",
    "    :return\n",
    "    The in-normalized data\n",
    "    \"\"\"\n",
    "#     std =np.std(data)\n",
    "#     mean = data.mean()\n",
    "#     max_v = data.max()\n",
    "    \n",
    "    return data * 4505.783\n",
    "\n",
    "    #return data * (max_v-mean) + mean\n",
    "\n",
    "def standardise(X, how='std=1', mean=200, std=400, midrange=None,\n",
    "                ptp=None):\n",
    "    \"\"\"Standardise.\n",
    "    ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std_in\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : matrix\n",
    "        Each sample is in range [0, 1]\n",
    "    how : str, {'range=2', 'std=1'}\n",
    "        'range=2' sets midrange to 0 and enforces\n",
    "        all values to be in the range [-1,1]\n",
    "        'std=1' sets mean = 0 and std = 1\n",
    "    Returns\n",
    "    -------\n",
    "    new_X : matrix\n",
    "        Same shape as `X`.  Sample is in range [lower, upper]\n",
    "    See also\n",
    "    --------\n",
    "    unstandardise\n",
    "    \"\"\"\n",
    "    if how == 'std=1':\n",
    "        if mean is None:\n",
    "            mean = X.mean()\n",
    "        if std is None:\n",
    "            std = X.std()\n",
    "        centered = X - mean\n",
    "        if std == 0:\n",
    "            return centered\n",
    "        else:\n",
    "            return centered / std\n",
    "    elif how == 'range=2':\n",
    "        if midrange is None:\n",
    "            midrange = (X.max() + X.min()) / 2\n",
    "        if ptp is None:\n",
    "            ptp = X.ptp()\n",
    "        return (X - midrange) / (ptp / 2)\n",
    "    else:\n",
    "        raise RuntimeError(\"unrecognised how '\" + how + \"'\")\n",
    "        \n",
    "def unstandardise(data, std=400, mean=200, maximum=None):\n",
    "    unstandardised_data = (data * std) + mean\n",
    "    if maximum is not None:\n",
    "        unstandardised_data *= maximum\n",
    "    return unstandardised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PPNy3dv4y24k",
    "outputId": "eb06a6c5-4253-4fbd-9f79-b1f2f9c34823"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model, Model, Input\n",
    "from keras.layers import Dense, Conv1D, GRU, LSTM, Bidirectional, Dropout,Conv2D\n",
    "from keras.layers import Reshape, BatchNormalization, Activation, Flatten, Concatenate\n",
    "from keras.models import Sequential\n",
    "\n",
    "def RNN_model(window_size):\n",
    "    '''Creates the RNN module described in the paper\n",
    "    '''\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1D Conv\n",
    "    model.add(Conv1D(16, 4, activation=\"linear\", input_shape=(window_size,1), padding=\"same\", strides=1))\n",
    "\n",
    "    #Bi-directional LSTMs\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True, stateful=False), merge_mode='concat'))\n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=False, stateful=False), merge_mode='concat'))\n",
    "\n",
    "    # Fully Connected Layers\n",
    "    model.add(Dense(128, activation='tanh'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    #plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def GRU_model(window_size):\n",
    "\n",
    "    '''Creates the GRU architecture described in the paper\n",
    "    '''\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1D Conv\n",
    "    model.add(Conv1D(16, 4, activation=\"relu\", padding=\"same\", strides=1, input_shape=(params['window_size'],1)))\n",
    "    model.add(Conv1D(8, 4, activation=\"relu\", padding=\"same\", strides=1))\n",
    "\n",
    "    # Bi-directional LSTMs\n",
    "    model.add(Bidirectional(GRU(128, return_sequences=True, stateful=False), merge_mode='concat'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Bidirectional(GRU(256, return_sequences=False, stateful=False), merge_mode='concat'))\n",
    "    model.add(Dropout(0.3))\n",
    "    # Fully Connected Layers\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def DAE_model(window_size):\n",
    "    '''Creates and returns the ShortSeq2Point Network\n",
    "     Based on: https://arxiv.org/pdf/1612.09106v3.pdf\n",
    "    '''\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1D Conv\n",
    "    model.add(Conv1D(30, 10, activation='relu', input_shape=(window_size,1), padding=\"same\", strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(30, 8, activation='relu', padding=\"same\", strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(40, 6, activation='relu', padding=\"same\", strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(50, 5, activation='relu', padding=\"same\", strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(50, 5, activation='relu', padding=\"same\", strides=1))\n",
    "    model.add(Dropout(0.2))\n",
    "    # Fully Connected Layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "def DresNET_model(window_size):\n",
    "    '''Creates the GRU architecture described in the paper\n",
    "    '''\n",
    "    def residual_block(filters,x,stride = 1,dilate = None):\n",
    "        resiual = x\n",
    "        out = BatchNormalization()(x)\n",
    "        out1 = Activation('relu')(out)\n",
    "        out = Conv1D(filters = filters,kernel_size = [3],dilation_rate = dilate,strides = [1],padding = 'same')(out1)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Activation('relu')(out)\n",
    "        out = Conv1D(filters = filters,kernel_size = [3],strides = [1],padding = 'same')(out)\n",
    "        out = BatchNormalization()(out)\n",
    "        out = Activation('relu')(out)\n",
    "        out = Conv1D(filters = filters,kernel_size = [1],dilation_rate = dilate,strides = [1],padding = 'same')(out)\n",
    "\n",
    "        if out1.shape[-1] != filters or stride == 1:\n",
    "            residual = Conv1D(filters = filters,kernel_size = [3],strides = [1],padding = 'same')(out1)\n",
    "            out = Concatenate()([residual,out])\n",
    "        return out\n",
    "\n",
    "    x = Input(shape = [window_size,1])\n",
    "    conv1 = Conv1D(filters = 30,kernel_size = [5],dilation_rate = [1],strides = [1],padding = 'same')(x)\n",
    "    bn = BatchNormalization()(conv1)\n",
    "    out = Activation('relu')(bn)\n",
    "    repetition = [3,4,6,3]\n",
    "    filter_num = [30,40,50,50]\n",
    "    dilations = [[1],[2],[3],[3]]\n",
    "    for i in range(len(repetition)):\n",
    "        for j in range(repetition[i]):\n",
    "            out = residual_block(filters = filter_num[i],dilate = dilations[i],x = out)\n",
    "\n",
    "    out = Flatten()(out)\n",
    "    out = Dense(units = 1)(out)\n",
    "    model = Model(x,out)\n",
    "    model.compile(optimizer = 'adam',loss = 'mse')\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EHJPt__pyuMk"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "from warnings import warn, filterwarnings\n",
    "\n",
    "import random\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nilmtk.disaggregate import Disaggregator\n",
    "from nilmtk.datastore import HDFDataStore\n",
    "\n",
    "\n",
    "\n",
    "class NeuralDisaggregator(Disaggregator):\n",
    "    '''Attempt to create a RNN Disaggregator\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    model : keras Sequential model\n",
    "    mmax : the maximum value of the aggregate data\n",
    "\n",
    "    MIN_CHUNK_LENGTH : int\n",
    "       the minimum length of an acceptable chunk\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, model, name,batch_size, window_size=100):\n",
    "        '''Initialize disaggregator\n",
    "        '''\n",
    "        self.MODEL_NAME = name\n",
    "        self.MIN_CHUNK_LENGTH = window_size\n",
    "        self.window_size = window_size\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "            \n",
    "    def disaggregate(self, mains, output_datastore, meter_metadata, **load_kwargs):\n",
    "        '''Disaggregate mains according to the model learnt previously.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mains : a nilmtk.ElecMeter of aggregate data\n",
    "        meter_metadata: a nilmtk.ElecMeter of the observed meter used for storing the metadata\n",
    "        output_datastore : instance of nilmtk.DataStore subclass\n",
    "            For storing power predictions from disaggregation algorithm.\n",
    "        **load_kwargs : key word arguments\n",
    "            Passed to `mains.power_series(**kwargs)`\n",
    "        '''\n",
    "\n",
    "        load_kwargs = self._pre_disaggregation_checks(load_kwargs)\n",
    "\n",
    "        load_kwargs.setdefault('sample_period', 60)\n",
    "        load_kwargs.setdefault('sections', mains.good_sections())\n",
    "\n",
    "        timeframes = []\n",
    "        building_path = '/building{}'.format(mains.building())\n",
    "        mains_data_location = building_path + '/elec/meter1'\n",
    "        data_is_available = False\n",
    "\n",
    "        for chunk in mains.power_series(**load_kwargs):\n",
    "            if len(chunk) < self.MIN_CHUNK_LENGTH:\n",
    "                continue\n",
    "            print(\"New sensible chunk: {}\".format(len(chunk)))\n",
    "\n",
    "            timeframes.append(chunk.timeframe)\n",
    "            measurement = chunk.name\n",
    "            #chunk2 = normalise(chunk)\n",
    "            chunk2=chunk\n",
    "            appliance_power = self.disaggregate_chunk(chunk2)\n",
    "            appliance_power[appliance_power < 0] = 0\n",
    "            #appliance_power = inversenormalise(appliance_power)\n",
    "\n",
    "            # Append prediction to output\n",
    "            data_is_available = True\n",
    "            cols = pd.MultiIndex.from_tuples([chunk.name])\n",
    "            meter_instance = meter_metadata.instance()\n",
    "            df = pd.DataFrame(\n",
    "                appliance_power.values, index=appliance_power.index,\n",
    "                columns=cols, dtype=\"float32\")\n",
    "            key = '{}/elec/meter{}'.format(building_path, meter_instance)\n",
    "            output_datastore.append(key, df)\n",
    "\n",
    "            # Append aggregate data to output\n",
    "            mains_df = pd.DataFrame(chunk, columns=cols, dtype=\"float32\")\n",
    "            output_datastore.append(key=mains_data_location, value=mains_df)\n",
    "\n",
    "        # Save metadata to output\n",
    "        if data_is_available:\n",
    "            self._save_metadata_for_disaggregation(\n",
    "                output_datastore=output_datastore,\n",
    "                sample_period=load_kwargs['sample_period'],\n",
    "                measurement=measurement,\n",
    "                timeframes=timeframes,\n",
    "                building=mains.building(),\n",
    "                meters=[meter_metadata]\n",
    "            )\n",
    "\n",
    "    def disaggregate_chunk(self, mains):\n",
    "        '''In-memory disaggregation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        mains : pd.Series of aggregate data\n",
    "        Returns\n",
    "        -------\n",
    "        appliance_powers : pd.DataFrame where each column represents a\n",
    "            disaggregated appliance.  Column names are the integer index\n",
    "            into `self.model` for the appliance in question.\n",
    "        '''\n",
    "        up_limit = len(mains)\n",
    "\n",
    "        mains.fillna(0, inplace=True)\n",
    "\n",
    "        X_batch = np.array(mains)\n",
    "        Y_len = len(X_batch)\n",
    "        indexer = np.arange(self.window_size)[None, :] + np.arange(len(X_batch)-self.window_size+1)[:, None]\n",
    "        X_batch = X_batch[indexer]\n",
    "        X_batch = np.reshape(X_batch, (X_batch.shape[0],X_batch.shape[1],1))\n",
    "\n",
    "        pred = self.model.predict(X_batch, batch_size=self.batch_size)\n",
    "        pred = np.reshape(pred, (len(pred)))\n",
    "        column = pd.Series(pred, index=mains.index[self.window_size-1:Y_len], name=0)\n",
    "        \n",
    "\n",
    "        appliance_powers_dict = {}\n",
    "        appliance_powers_dict[0] = column\n",
    "        appliance_powers = pd.DataFrame(appliance_powers_dict)\n",
    "        return appliance_powers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DUFVTW1ayl_Z"
   },
   "outputs": [],
   "source": [
    "\n",
    "from nilmtk.electric import align_two_meters\n",
    "import numpy as np\n",
    "\n",
    "def tp_tn_fp_fn(states_pred, states_ground):\n",
    "    tp = np.sum(np.logical_and(states_pred == 1, states_ground == 1))\n",
    "    fp = np.sum(np.logical_and(states_pred == 1, states_ground == 0))\n",
    "    fn = np.sum(np.logical_and(states_pred == 0, states_ground == 1))\n",
    "    tn = np.sum(np.logical_and(states_pred == 0, states_ground == 0))\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def recall_precision_accuracy_f1(pred, ground):\n",
    "    aligned_meters = align_two_meters(pred, ground)\n",
    "    threshold = ground.on_power_threshold()\n",
    "    chunk_results = []\n",
    "    sum_samples = 0.0\n",
    "    for chunk in aligned_meters:\n",
    "        sum_samples += len(chunk)\n",
    "        pr = np.array([0 if (p)<threshold else 1 for p in chunk.iloc[:,0]])\n",
    "        gr = np.array([0 if p<threshold else 1 for p in chunk.iloc[:,1]])\n",
    "\n",
    "        tp, tn, fp, fn = tp_tn_fp_fn(pr,gr)\n",
    "        p = sum(pr)\n",
    "        n = len(pr) - p\n",
    "\n",
    "        chunk_results.append([tp,tn,fp,fn,p,n])\n",
    "\n",
    "    if sum_samples == 0:\n",
    "        return None\n",
    "    else:\n",
    "        [tp,tn,fp,fn,p,n] = np.sum(chunk_results, axis=0)\n",
    "\n",
    "        res_recall = recall(tp,fn)\n",
    "        res_precision = precision(tp,fp)\n",
    "        res_f1 = f1(res_precision,res_recall)\n",
    "        res_accuracy = accuracy(tp,tn,p,n)\n",
    "\n",
    "        return (res_recall,res_precision,res_accuracy,res_f1)\n",
    "\n",
    "def relative_error_total_energy(pred, ground):\n",
    "    aligned_meters = align_two_meters(pred, ground)\n",
    "    chunk_results = []\n",
    "    sum_samples = 0.0\n",
    "    for chunk in aligned_meters:\n",
    "        chunk.fillna(0, inplace=True)\n",
    "        sum_samples += len(chunk)\n",
    "        E_pred = sum(chunk.iloc[:,0])\n",
    "        E_ground = sum(chunk.iloc[:,1])\n",
    "\n",
    "        chunk_results.append([\n",
    "                            E_pred,\n",
    "                            E_ground\n",
    "                            ])\n",
    "    if sum_samples == 0:\n",
    "        return None\n",
    "    else:\n",
    "        [E_pred, E_ground] = np.sum(chunk_results,axis=0)\n",
    "        return abs(E_pred - E_ground) / float(max(E_pred,E_ground))\n",
    "\n",
    "def mean_absolute_error(pred, ground):\n",
    "    aligned_meters = align_two_meters(pred, ground)\n",
    "    total_sum = 0.0\n",
    "    sum_samples = 0.0\n",
    "    for chunk in aligned_meters:\n",
    "        chunk.fillna(0, inplace=True)\n",
    "        sum_samples += len(chunk)\n",
    "        total_sum += sum(abs((chunk.iloc[:,0]) - chunk.iloc[:,1]))\n",
    "    if sum_samples == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return total_sum / sum_samples\n",
    "\n",
    "\n",
    "def recall(tp,fn):\n",
    "    return tp/float(tp+fn)\n",
    "\n",
    "def precision(tp,fp):\n",
    "    return tp/float(tp+fp)\n",
    "\n",
    "def f1(prec,rec):\n",
    "    return 2 * (prec*rec) / float(prec+rec)\n",
    "\n",
    "def accuracy(tp, tn, p, n):\n",
    "    return (tp + tn) / float(p + n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C8sgly5YyimH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Batch_Generator():\n",
    "\n",
    "    def __init__(self, batch_size, window_size, model_name, shuffle=True):\n",
    "\n",
    "        self.name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.window_size = window_size\n",
    "        \n",
    "    def num_epochs(self, inputs):\n",
    "        \n",
    "        batch_size = int(self.batch_size / len(inputs))\n",
    "        num_of_batches = [(int((len(inputs[i])-self.window_size+1) / batch_size) - 1) for i in range(len(inputs))]\n",
    "        n_epochs = min(num_of_batches)\n",
    "        \n",
    "        return n_epochs\n",
    "\n",
    "    def generator(self, inputs, targets):\n",
    "      \n",
    "        num_meters = len(inputs)\n",
    "        batch_size = int(self.batch_size / num_meters)\n",
    "        #num_of_batches = [(int(len(inputs[i]) / batch_size) - 1) for i in range(len(inputs))]\n",
    "\n",
    "        n_epochs = self.num_epochs(inputs)\n",
    "\n",
    "\n",
    "        # Batch indexes\n",
    "        while True:\n",
    "          self.indexes = list(range(n_epochs))\n",
    "\n",
    "          if self.shuffle == True:\n",
    "              np.random.shuffle(self.indexes)\n",
    "\n",
    "          for ei, e in enumerate(self.indexes):\n",
    "\n",
    "              offset = e * batch_size\n",
    "\n",
    "              # Initialization\n",
    "              X_batch = np.zeros((batch_size * num_meters, self.window_size, 1))  # (128,100,1)\n",
    "              Y_batch = np.zeros((batch_size * num_meters, 1))  # (128,1)\n",
    "\n",
    "              # Create a batch out of data from all buildings\n",
    "              for i in range(num_meters):\n",
    "                  mainpart = inputs[i]\n",
    "                  meterpart = targets[i]\n",
    "\n",
    "                  indexer = np.arange(self.window_size)[None, :] + np.arange(len(inputs[i])-self.window_size+1)[offset:offset + batch_size, None]\n",
    "\n",
    "                  mainpart = mainpart[indexer]\n",
    "                  meterpart = meterpart[self.window_size - 1:][offset:offset + batch_size]\n",
    "\n",
    "                  X = np.reshape(mainpart, (batch_size, self.window_size, 1))\n",
    "                  Y = np.reshape(meterpart, (batch_size, 1))\n",
    "\n",
    "                  X_batch[i * batch_size:(i + 1) * batch_size] = np.array(X)\n",
    "                  Y_batch[i * batch_size:(i + 1) * batch_size] = np.array(Y)\n",
    "                  \n",
    "              \n",
    "\n",
    "#               # Shuffle data\n",
    "#               if self.shuffle == True:\n",
    "#                 p = np.random.permutation(len(X_batch))\n",
    "#                 X_batch, Y_batch = X_batch[p], Y_batch[p]\n",
    "       \n",
    "              yield X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nXmq80OAyVQD",
    "outputId": "bcb9bf11-207b-48cb-c85f-1705ba45426e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0701 19:25:28.084713 139776801200000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0701 19:25:28.116638 139776801200000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0701 19:25:28.124219 139776801200000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0701 19:25:28.246715 139776801200000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0701 19:25:34.154254 139776801200000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 100, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 100, 30)      180         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 100, 30)      120         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 100, 30)      0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 100, 30)      120         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 100, 30)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 100, 30)      2730        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 100, 30)      120         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 100, 30)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 100, 30)      2730        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 100, 30)      120         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 100, 30)      0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 100, 30)      2730        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 100, 30)      930         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 100, 60)      0           conv1d_5[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 100, 60)      240         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 100, 60)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 100, 30)      5430        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 100, 30)      120         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 100, 30)      0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 100, 30)      2730        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 100, 30)      120         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 100, 30)      0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 100, 30)      5430        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 100, 30)      930         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 100, 60)      0           conv1d_9[0][0]                   \n",
      "                                                                 conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 100, 60)      240         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 100, 60)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 100, 30)      5430        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 100, 30)      120         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 100, 30)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 100, 30)      2730        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 100, 30)      120         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 100, 30)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 100, 30)      5430        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 100, 30)      930         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 100, 60)      0           conv1d_13[0][0]                  \n",
      "                                                                 conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 100, 60)      240         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 100, 60)      0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 100, 40)      7240        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 100, 40)      160         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 100, 40)      0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 100, 40)      4840        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 100, 40)      160         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 100, 40)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 100, 40)      7240        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 100, 40)      1640        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 100, 80)      0           conv1d_17[0][0]                  \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 100, 80)      320         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 100, 80)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 100, 40)      9640        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 100, 40)      160         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 100, 40)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 100, 40)      4840        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 100, 40)      160         conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 100, 40)      0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 100, 40)      9640        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 100, 40)      1640        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 100, 80)      0           conv1d_21[0][0]                  \n",
      "                                                                 conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 100, 80)      320         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 100, 80)      0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 100, 40)      9640        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 100, 40)      160         conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 100, 40)      0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 100, 40)      4840        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 100, 40)      160         conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 100, 40)      0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 100, 40)      9640        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 100, 40)      1640        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 100, 80)      0           conv1d_25[0][0]                  \n",
      "                                                                 conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 100, 80)      320         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 100, 80)      0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 100, 40)      9640        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 100, 40)      160         conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 100, 40)      0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 100, 40)      4840        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 100, 40)      160         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 100, 40)      0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 100, 40)      9640        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 100, 40)      1640        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 100, 80)      0           conv1d_29[0][0]                  \n",
      "                                                                 conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 100, 80)      320         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 100, 80)      0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 100, 50)      12050       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 100, 50)      200         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 100, 50)      0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 100, 50)      7550        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 100, 50)      200         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 100, 50)      0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 100, 50)      12050       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 100, 50)      2550        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 100, 100)     0           conv1d_33[0][0]                  \n",
      "                                                                 conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 100, 100)     400         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 100, 100)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 100, 50)      15050       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 100, 50)      200         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 100, 50)      0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 100, 50)      7550        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 100, 50)      200         conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 100, 50)      0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 100, 50)      15050       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 100, 50)      2550        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 100, 100)     0           conv1d_37[0][0]                  \n",
      "                                                                 conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 100, 100)     400         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 100, 100)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 100, 50)      15050       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 100, 50)      200         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 100, 50)      0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 100, 50)      7550        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 100, 50)      200         conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 100, 50)      0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 100, 50)      15050       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 100, 50)      2550        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 100, 100)     0           conv1d_41[0][0]                  \n",
      "                                                                 conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 100, 100)     400         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 100, 100)     0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 100, 50)      15050       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 100, 50)      200         conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 100, 50)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 100, 50)      7550        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 100, 50)      200         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 100, 50)      0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 100, 50)      15050       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 100, 50)      2550        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 100, 100)     0           conv1d_45[0][0]                  \n",
      "                                                                 conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 100, 100)     400         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 100, 100)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 100, 50)      15050       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 100, 50)      200         conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 100, 50)      0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 100, 50)      7550        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 100, 50)      200         conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 100, 50)      0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 100, 50)      15050       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 100, 50)      2550        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 100, 100)     0           conv1d_49[0][0]                  \n",
      "                                                                 conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 100, 100)     400         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 100, 100)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 100, 50)      15050       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 100, 50)      200         conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 100, 50)      0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 100, 50)      7550        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 100, 50)      200         conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 100, 50)      0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 100, 50)      15050       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 100, 50)      2550        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 100, 100)     0           conv1d_53[0][0]                  \n",
      "                                                                 conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 100, 100)     400         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 100, 100)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 100, 50)      15050       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 100, 50)      200         conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 100, 50)      0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 100, 50)      7550        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 100, 50)      200         conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 100, 50)      0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 100, 50)      15050       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 100, 50)      2550        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 100, 100)     0           conv1d_57[0][0]                  \n",
      "                                                                 conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 100, 100)     400         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 100, 100)     0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 100, 50)      15050       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 100, 50)      200         conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 100, 50)      0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 100, 50)      7550        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 100, 50)      200         conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 100, 50)      0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 100, 50)      15050       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 100, 50)      2550        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 100, 100)     0           conv1d_61[0][0]                  \n",
      "                                                                 conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 100, 100)     400         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 100, 100)     0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 100, 50)      15050       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 100, 50)      200         conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 100, 50)      0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 100, 50)      7550        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 100, 50)      200         conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 100, 50)      0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 100, 50)      15050       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 100, 50)      2550        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 100, 100)     0           conv1d_65[0][0]                  \n",
      "                                                                 conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10000)        0           concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            10001       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 513,421\n",
      "Trainable params: 507,901\n",
      "Non-trainable params: 5,520\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "*********Training*********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0701 19:25:41.986005 139776801200000 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "276657/276657 [==============================] - 257s 930us/step - loss: 14670.1752\n",
      "Epoch 2/50\n",
      "276657/276657 [==============================] - 232s 840us/step - loss: 11504.9386\n",
      "Epoch 3/50\n",
      "276657/276657 [==============================] - 231s 834us/step - loss: 9934.4783\n",
      "Epoch 4/50\n",
      "276657/276657 [==============================] - 230s 833us/step - loss: 9381.3232\n",
      "Epoch 5/50\n",
      "276657/276657 [==============================] - 232s 838us/step - loss: 8275.8949\n",
      "Epoch 6/50\n",
      "276657/276657 [==============================] - 231s 837us/step - loss: 7926.7150\n",
      "Epoch 7/50\n",
      "276657/276657 [==============================] - 231s 835us/step - loss: 6869.8769\n",
      "Epoch 8/50\n",
      "276657/276657 [==============================] - 231s 834us/step - loss: 6542.6492\n",
      "Epoch 9/50\n",
      "276657/276657 [==============================] - 231s 835us/step - loss: 5430.4085\n",
      "Epoch 10/50\n",
      "276657/276657 [==============================] - 231s 835us/step - loss: 5177.9739\n",
      "Epoch 11/50\n",
      "276657/276657 [==============================] - 232s 840us/step - loss: 5157.4298\n",
      "Epoch 12/50\n",
      "276657/276657 [==============================] - 232s 839us/step - loss: 4273.9906\n",
      "Epoch 13/50\n",
      "276657/276657 [==============================] - 232s 837us/step - loss: 4160.1054\n",
      "Epoch 14/50\n",
      "276657/276657 [==============================] - 231s 837us/step - loss: 4053.3727\n",
      "Epoch 15/50\n",
      "276657/276657 [==============================] - 230s 833us/step - loss: 4119.6968\n",
      "Epoch 16/50\n",
      "276657/276657 [==============================] - 228s 826us/step - loss: 3864.3105\n",
      "Epoch 17/50\n",
      "276657/276657 [==============================] - 228s 823us/step - loss: 3724.3681\n",
      "Epoch 18/50\n",
      "276657/276657 [==============================] - 238s 859us/step - loss: 3265.2161\n",
      "Epoch 19/50\n",
      "276657/276657 [==============================] - 234s 847us/step - loss: 3676.7614\n",
      "Epoch 20/50\n",
      "276657/276657 [==============================] - 234s 844us/step - loss: 3019.7742\n",
      "Epoch 21/50\n",
      "276657/276657 [==============================] - 234s 846us/step - loss: 3066.6357\n",
      "Epoch 22/50\n",
      "276657/276657 [==============================] - 234s 844us/step - loss: 2877.3670\n",
      "Epoch 23/50\n",
      "276657/276657 [==============================] - 236s 852us/step - loss: 2960.5269\n",
      "Epoch 24/50\n",
      "276657/276657 [==============================] - 235s 849us/step - loss: 2619.7361\n",
      "Epoch 25/50\n",
      "276657/276657 [==============================] - 237s 856us/step - loss: 2850.5870\n",
      "Epoch 26/50\n",
      "276657/276657 [==============================] - 237s 858us/step - loss: 2590.6661\n",
      "Epoch 27/50\n",
      "276657/276657 [==============================] - 236s 854us/step - loss: 2639.4959\n",
      "Epoch 28/50\n",
      "261376/276657 [===========================>..] - ETA: 12s - loss: 2776.4862Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import time\n",
    "\n",
    "\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
    "#from disaggregator import NeuralDisaggregator\n",
    "#from dataset_processing import load_dataset, data_processing\n",
    "#from batch_generator import Batch_Generator\n",
    "#from models import GRU_model, RNN_model, DAE_model, DresNET_model\n",
    "from keras.models import load_model\n",
    "import metrics\n",
    "import nilm_metric as nm\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# =====Define paramaters======\n",
    "info = {'filename': 'drive/My Drive/Dissertation/redd.h5',\n",
    "        'meter_label': 'microwave',  # [\"kettle\" , \"microwave\" , \"dishwasher\" , \"fridge\" , \"washing_machine\"]\n",
    "        'train_building': [1],\n",
    "        'test_building': 1,\n",
    "        'sample_period': 3\n",
    "       }\n",
    "\n",
    "# Parameters\n",
    "params = {'batch_size': 128,\n",
    "          'window_size': 100,\n",
    "          'model_name': 'DresNET',\n",
    "          'shuffle': True}\n",
    "\n",
    "#Define the training intervals for each house\n",
    "window_per_house = {1: (None, '2011-04-28'), \n",
    "                2: (\"2013-04-16\", \"2013-10-10\"), \n",
    "                3: ('2013-02-27' , '2013-04-08 '), \n",
    "                4: (\"2013-03-09\", \"2013-10-01\"), \n",
    "                5: (\"2014-06-29\", None)}\n",
    "\n",
    "\n",
    "test_window = {1: ('2011-05-01', '2011-05-06')}\n",
    "\n",
    "\n",
    "num_epochs = 8\n",
    "# =====Load Dataset======\n",
    "train_meterlist, train_mainlist, test_meterlist, test_mainlist = load_dataset(window_per_house,test_window, **info)\n",
    "\n",
    "train_x, train_y = data_processing(train_mainlist, train_meterlist, window_size=params['window_size'])\n",
    "\n",
    "\n",
    "\n",
    "if params['model_name'] == 'LSTM':\n",
    "    model = RNN_model(params['window_size'])\n",
    "\n",
    "elif params['model_name'] == 'GRU':\n",
    "    model = GRU_model(params['window_size'])\n",
    "\n",
    "elif params['model_name'] == 'DAE':\n",
    "    model = DAE_model(params['window_size'])\n",
    "\n",
    "elif params['model_name'] == 'DresNET':\n",
    "    model = DresNET_model(params['window_size'])\n",
    "\n",
    "\n",
    "\n",
    "# Training\n",
    "filepath_checkpoint = \"UKDALE-RNN-h \" + str(info['train_building']) + str(info['meter_label']) + ' epo.hdf5'\n",
    "filepath = 'drive/My Drive/Dissertation/UKDALE-GRU-microwave-5epochs.h5'\n",
    "filepath = 'UKDALE-GRU-fridge-8epochs.h5'\n",
    "\n",
    "# Batch generator\n",
    "gen = Batch_Generator(**params)\n",
    "t = gen.generator(train_x, train_y)\n",
    "steps_epochs = gen.num_epochs(train_x)\n",
    "\n",
    "\n",
    "\n",
    "mode = 'training'\n",
    "\n",
    "if mode == 'training':\n",
    "\n",
    "    print(\"*********Training*********\")\n",
    "    start = time.time()\n",
    "    indexer = np.arange(params['window_size'])[None, :] + np.arange(len(train_x[0])-params['window_size']+1)[:, None]\n",
    "    x = train_x[0][indexer]\n",
    "    y = train_y[0][params['window_size']-1:]\n",
    "\n",
    "    x = np.reshape(x, (x.shape[0],params['window_size'],1))\n",
    "    y = np.reshape(y, (y.shape[0],1))\n",
    "    model.fit(x, y, epochs=50, batch_size=128, shuffle=True)\n",
    "\n",
    "#     checkpointer = ModelCheckpoint(filepath_checkpoint,\n",
    "#                                    verbose=1, save_best_only=True)\n",
    "#     model.fit_generator(t, \n",
    "#                         steps_per_epoch = steps_epochs, \n",
    "#                         epochs=num_epochs,\n",
    "#                         use_multiprocessing=True,\n",
    "#                         workers=6, \n",
    "#                         callbacks=[checkpointer])\n",
    "\n",
    "    \n",
    "    \n",
    "    model.save(\"UKDALE-{}-{}-{}epochs.h5\".format(params['model_name'], \n",
    "                                                     info['meter_label'],\n",
    "                                                      num_epochs))\n",
    "    \n",
    "    end = time.time()\n",
    "    print('### Total trainning time cost: {} ###'.format(str(end - start)))\n",
    "\n",
    "elif mode == 'loading':\n",
    "    # load checkpoints weights\n",
    "    print(filepath_checkpoint)\n",
    "    model.load_weights(filepath_checkpoint)\n",
    "    \n",
    "elif mode == 'load_pretrained':\n",
    "    #load pretrained model\n",
    "    model = load_model(filepath)\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "     \n",
    "    \n",
    "# print(\"*********Disaggregate*********\")\n",
    "disaggregator = NeuralDisaggregator(model, name = params['model_name'],batch_size = params['batch_size'], window_size = params['window_size'])\n",
    "disag_filename = \"disag-out.h5\"\n",
    "output = HDFDataStore(disag_filename, 'w')\n",
    "disaggregator.disaggregate(test_mainlist, output, test_meterlist, sample_period = info['sample_period'])\n",
    "output.close()\n",
    "\n",
    "\n",
    "print(\"========== RESULTS ============\")\n",
    "meter_key = info['meter_label']\n",
    "result = DataSet(disag_filename)\n",
    "res_elec = result.buildings[info['test_building']].elec\n",
    "#print(test_meterlist.power_series_all_data())\n",
    "#print(res_elec[meter_key].power_series_all_data())\n",
    "rpaf = metrics.recall_precision_accuracy_f1(res_elec[meter_key], test_meterlist)\n",
    "print(\"============ Recall: {}\".format(rpaf[0]))\n",
    "print(\"============ Precision: {}\".format(rpaf[1]))\n",
    "print(\"============ Accuracy: {}\".format(rpaf[2]))\n",
    "print(\"============ F1 Score: {}\".format(rpaf[3]))\n",
    "\n",
    "print(\"============ Relative error in total energy: {}\".format(metrics.relative_error_total_energy(res_elec[meter_key], test_meterlist)))\n",
    "print(\"============ Mean absolute error(in Watts): {}\".format(metrics.mean_absolute_error(res_elec[meter_key], test_meterlist)))\n",
    "\n",
    "\n",
    "aligned_meters = align_two_meters(res_elec[meter_key], test_meterlist)\n",
    "#threshold = ground.on_power_threshold()\n",
    "meters = next(aligned_meters)\n",
    "threshold = 10\n",
    "predict = meters['master']\n",
    "ground = meters['slave']\n",
    "print()\n",
    "print('F1:{0}'.format(nm.get_F1(ground, predict, threshold)))\n",
    "print('Mean absolute error(in Watts):{0}'.format(nm.get_abs_error(ground, predict)))\n",
    "print('Relative error:{0}'.format(nm.get_relative_error(ground, predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "khSOeGHWujUc",
    "outputId": "7e209909-4455-4e14-f9bb-a0e6d88db34f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1fcc171cf8>]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAD8CAYAAACPWyg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERFJ2f8AscHSv9M6o3sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(test_meterlist.power_series_all_data()[0:10000])\n",
    "plt.plot(res_elec[meter_key].power_series_all_data()[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "colab_type": "code",
    "id": "Byopt5dBLlu8",
    "outputId": "806d5845-b3bd-4219-d99f-11cce3d5c9cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== RESULTS ============\n",
      "============ Recall: 0.05469369267353641\n",
      "============ Precision: 0.3484848484848485\n",
      "============ Accuracy: 0.7634196864690689\n",
      "============ F1 Score: 0.09454830184985809\n",
      "============ Relative error in total energy: 0.24504562417340078\n",
      "============ Mean absolute error(in Watts): 6.284404947856084\n",
      "\n",
      "tp=11031.0\n",
      "fn=10559.0\n",
      "0.5109309865678555\n",
      "tp=11031.0\n",
      "fp=11043.0\n",
      "0.49972818700733895\n",
      "F1:0.5052674972517407\n",
      "Mean absolute error(in Watts):7.751648902893066\n",
      "Relative error:0.357479989528656\n"
     ]
    }
   ],
   "source": [
    "print(\"========== RESULTS ============\")\n",
    "meter_key = info['meter_label']\n",
    "result = DataSet(disag_filename)\n",
    "res_elec = result.buildings[info['test_building']].elec\n",
    "#print(test_meterlist.power_series_all_data())\n",
    "#print(res_elec[meter_key].power_series_all_data())\n",
    "rpaf = metrics.recall_precision_accuracy_f1(res_elec[meter_key], test_meterlist)\n",
    "print(\"============ Recall: {}\".format(rpaf[0]))\n",
    "print(\"============ Precision: {}\".format(rpaf[1]))\n",
    "print(\"============ Accuracy: {}\".format(rpaf[2]))\n",
    "print(\"============ F1 Score: {}\".format(rpaf[3]))\n",
    "\n",
    "print(\"============ Relative error in total energy: {}\".format(metrics.relative_error_total_energy(res_elec[meter_key], test_meterlist)))\n",
    "print(\"============ Mean absolute error(in Watts): {}\".format(metrics.mean_absolute_error(res_elec[meter_key], test_meterlist)))\n",
    "\n",
    "\n",
    "aligned_meters = align_two_meters(res_elec[meter_key], test_meterlist)\n",
    "#threshold = ground.on_power_threshold()\n",
    "meters = next(aligned_meters)\n",
    "threshold = 10\n",
    "predict = meters['master']\n",
    "ground = meters['slave']\n",
    "print()\n",
    "print('F1:{0}'.format(nm.get_F1(ground, predict, threshold)))\n",
    "print('Mean absolute error(in Watts):{0}'.format(nm.get_abs_error(ground, predict)))\n",
    "print('Relative error:{0}'.format(nm.get_relative_error(ground, predict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjXz1oEQvjEs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "e18_win50_frigde_redd_S2P.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
