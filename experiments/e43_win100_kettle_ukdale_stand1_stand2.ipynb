{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "e43_win100_kettle_ukdale_stand1_stand2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz9jitiMmFkE",
        "colab_type": "code",
        "outputId": "87479c45-df71-4d58-ab13-51f8a4c91566",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "'''\n",
        "Model: DreNet \n",
        "Aplpiance: microwave\n",
        "Data: Redd\n",
        "\n",
        "Method:S2P\n",
        "Normalization: no norm\n",
        "batch_size: 128,\n",
        "window_size: 100\n",
        "shuffle: True\n",
        "\n",
        "num epochs=50\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nModel: DreNet \\nAplpiance: microwave\\nData: Redd\\n\\nMethod:S2P\\nNormalization: no norm\\nbatch_size: 128,\\nwindow_size: 100\\nshuffle: True\\n\\nnum epochs=50\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObzzZOy1zAzo",
        "colab_type": "code",
        "outputId": "25cbee1d-7c1a-4bf4-a397-ae1d9eab9215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "sys.path.insert(0,'drive/My Drive/Dissertation')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amHn1qgwzEI2",
        "colab_type": "code",
        "outputId": "a6ea651e-37e4-47fe-f8ef-f1627e151e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pip install git+git://github.com/nilmtk/nilmtk.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/nilmtk/nilmtk.git\n",
            "  Cloning git://github.com/nilmtk/nilmtk.git to /tmp/pip-req-build-k42kxyqn\n",
            "  Running command git clone -q git://github.com/nilmtk/nilmtk.git /tmp/pip-req-build-k42kxyqn\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (1.12.0)\n",
            "Collecting psycopg2-binary (from nilmtk==0.3.0.dev0+git.511e8e8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/35/75c9c2d9cfc073ab6c42b2d8e91ff58c9b99f4ed7ed56b36647642e6080e/psycopg2_binary-2.8.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas==0.24.2 in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (0.24.2)\n",
            "Collecting networkx==2.1 (from nilmtk==0.3.0.dev0+git.511e8e8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/42/f951cc6838a4dff6ce57211c4d7f8444809ccbe2134179950301e5c4c83c/networkx-2.1.zip (1.6MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (1.3.0)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (3.4.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.2 in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (0.21.2)\n",
            "Collecting hmmlearn>=0.2.1 (from nilmtk==0.3.0.dev0+git.511e8e8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/c5/91b43156b193d180ed94069269bcf88d3c7c6e54514a8482050fa9995e10/hmmlearn-0.2.2.tar.gz (146kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 49.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (3.13)\n",
            "Requirement already satisfied: matplotlib>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (3.0.3)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from nilmtk==0.3.0.dev0+git.511e8e8) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->nilmtk==0.3.0.dev0+git.511e8e8) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->nilmtk==0.3.0.dev0+git.511e8e8) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.2->nilmtk==0.3.0.dev0+git.511e8e8) (2018.9)\n",
            "Requirement already satisfied: decorator>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from networkx==2.1->nilmtk==0.3.0.dev0+git.511e8e8) (4.4.0)\n",
            "Requirement already satisfied: numexpr>=2.5.2 in /usr/local/lib/python3.6/dist-packages (from tables->nilmtk==0.3.0.dev0+git.511e8e8) (2.6.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.2->nilmtk==0.3.0.dev0+git.511e8e8) (0.13.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.0->nilmtk==0.3.0.dev0+git.511e8e8) (2.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.0->nilmtk==0.3.0.dev0+git.511e8e8) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.0->nilmtk==0.3.0.dev0+git.511e8e8) (0.10.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (7.4.2)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (6.0.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.5.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (5.2.2)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (5.5.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=2.2.0->nilmtk==0.3.0.dev0+git.511e8e8) (41.0.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.4.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (5.5.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.4.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (3.4.2)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.3.2)\n",
            "Collecting prompt-toolkit<2.1.0,>=2.0.0 (from jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/9b1dd14ef45345f186ef69d175bdd2491c40ab1dfa4b2b3e4352df719ed7/prompt_toolkit-2.0.9-py3-none-any.whl (337kB)\n",
            "\u001b[K     |████████████████████████████████| 337kB 46.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (5.2.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (2.1.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (2.10.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.8.2)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.5.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (1.4.2)\n",
            "Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.8.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (3.1.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.4.2)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.3)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (2.6.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (4.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.1.7)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (17.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter->nilmtk==0.3.0.dev0+git.511e8e8) (0.5.1)\n",
            "Building wheels for collected packages: nilmtk, networkx, hmmlearn\n",
            "  Building wheel for nilmtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-n9ljek8l/wheels/71/84/2f/eca0fb8014a0fe59881ab1a3e3374f4108211de4c7c3081e8d\n",
            "  Building wheel for networkx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/c0/34/6f98693a554301bdb405f8d65d95bbcd3e50180cbfdd98a94e\n",
            "  Building wheel for hmmlearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/b6/0e/63a865a30e21e01d04f417d8995fbfb793d6bd464707efc546\n",
            "Successfully built nilmtk networkx hmmlearn\n",
            "\u001b[31mERROR: ipython 5.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.4, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: psycopg2-binary, networkx, hmmlearn, nilmtk, prompt-toolkit\n",
            "  Found existing installation: networkx 2.3\n",
            "    Uninstalling networkx-2.3:\n",
            "      Successfully uninstalled networkx-2.3\n",
            "  Found existing installation: prompt-toolkit 1.0.16\n",
            "    Uninstalling prompt-toolkit-1.0.16:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.16\n",
            "Successfully installed hmmlearn-0.2.2 networkx-2.1 nilmtk-0.3.0.dev0+git.511e8e8 prompt-toolkit-2.0.9 psycopg2-binary-2.8.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP1czK5szE76",
        "colab_type": "code",
        "outputId": "d7fa8dea-12e0-4134-d140-5d401191263f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "pip install git+git://github.com/nilmtk/nilm_metadata.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/nilmtk/nilm_metadata.git\n",
            "  Cloning git://github.com/nilmtk/nilm_metadata.git to /tmp/pip-req-build-gkyjgl5z\n",
            "  Running command git clone -q git://github.com/nilmtk/nilm_metadata.git /tmp/pip-req-build-gkyjgl5z\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from nilm-metadata==0.2.3) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nilm-metadata==0.2.3) (1.12.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from nilm-metadata==0.2.3) (0.24.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->nilm-metadata==0.2.3) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas->nilm-metadata==0.2.3) (1.16.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->nilm-metadata==0.2.3) (2.5.3)\n",
            "Building wheels for collected packages: nilm-metadata\n",
            "  Building wheel for nilm-metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-m8jc03rd/wheels/75/e0/6d/1ec555a322c151fe20b4c9834753a692203b1f62a66b3ee235\n",
            "Successfully built nilm-metadata\n",
            "Installing collected packages: nilm-metadata\n",
            "Successfully installed nilm-metadata-0.2.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLVywoaWzG-s",
        "colab_type": "code",
        "outputId": "0f3755aa-6580-43f0-e9ec-9a2e687797dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "pip install pandas==0.24.0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandas==0.24.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/e1/4a63ed31e1b1362d40ce845a5735c717a959bda992669468dae3420af2cd/pandas-0.24.0-cp36-cp36m-manylinux1_x86_64.whl (10.1MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.0) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.0) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas==0.24.0) (1.16.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.0->pandas==0.24.0) (1.12.0)\n",
            "\u001b[31mERROR: nilmtk 0.3.0.dev0+git.511e8e8 has requirement pandas==0.24.2, but you'll have pandas 0.24.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pandas\n",
            "  Found existing installation: pandas 0.24.2\n",
            "    Uninstalling pandas-0.24.2:\n",
            "      Successfully uninstalled pandas-0.24.2\n",
            "Successfully installed pandas-0.24.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVqjo-MkycMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import time\n",
        "\n",
        "from matplotlib import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
        "\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "\n",
        "\n",
        "\n",
        "def load_dataset(window_per_house,test_window, filename, meter_label, train_building, test_building, **load_kwargs):\n",
        "    \n",
        "    #Load datasets\n",
        "    train = DataSet(filename)\n",
        "    test = DataSet(filename)\n",
        "\n",
        "    #train.set_window(start=start_train, end=end_train)\n",
        "    test.set_window(*test_window[test_building])\n",
        "\n",
        "    train_mainlist = []\n",
        "    train_meterlist = []\n",
        "    for building_id, building in train.buildings.items():\n",
        "        if building_id in train_building:\n",
        "            train.set_window(*window_per_house[building_id])\n",
        "            y = building.elec[meter_label]\n",
        "            \n",
        "            if filename[-7:] == 'redd.h5':\n",
        "                x = building.elec.mains().all_meters()[0] \n",
        "                \n",
        "            else:\n",
        "                x = building.elec.mains()\n",
        "                \n",
        "            train_mainlist.append(x.power_series_all_data(**load_kwargs))\n",
        "            train_meterlist.append(y.power_series_all_data(**load_kwargs))\n",
        "            \n",
        "\n",
        "    test_meterlist = test.buildings[test_building].elec[meter_label]\n",
        "    \n",
        "    if filename[-7:] == 'redd.h5':\n",
        "        test_mainlist = test.buildings[test_building].elec.mains().all_meters()[0]\n",
        "    else:\n",
        "        test_mainlist = test.buildings[test_building].elec.mains()\n",
        "\n",
        "    assert len(train_mainlist) == len(train_meterlist), \"The number of main and apliances meters must be equal\"\n",
        "\n",
        "    return train_meterlist, train_mainlist, test_meterlist, test_mainlist\n",
        "\n",
        "\n",
        "def data_processing(train_mainlist, train_meterlist, window_size):\n",
        "    '''Data processing\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    train_mainlist : a list of nilmtk.ElecMeter objects for the aggregate data of each building\n",
        "    train_meterlist : a list of nilmtk.ElecMeter objects for the meter data of each building\n",
        "    '''\n",
        "\n",
        "    # Normalize the data\n",
        "    norm = Data_normalization()\n",
        "    train_x = [norm.standardise(data) for data in train_mainlist]\n",
        "    train_y = [norm.standardise2(data) for data in train_meterlist]\n",
        "    \n",
        "    #train_x = [data for data in train_mainlist]\n",
        "    #train_y = [data for data in train_meterlist]\n",
        "\n",
        "    # replca NaN values and\n",
        "    for i in range(len(train_x)):\n",
        "        train_x[i].fillna(0, inplace=True)\n",
        "        train_y[i].fillna(0, inplace=True)\n",
        "        ix = train_x[i].index.intersection(train_y[i].index)\n",
        "\n",
        "        train_x[i] = train_x[i][ix].values\n",
        "        train_y[i] = train_y[i][ix].values\n",
        "\n",
        "    return train_x, train_y, norm\n",
        "\n",
        "\n",
        "\n",
        "# def normalise(data):\n",
        "#     \"\"\"\n",
        "#     Perform the normalisation (x-min(x))/(max(x)-min(x)).\n",
        "#     --------------------------------------\n",
        "#     :arg\n",
        "#     data: data that needs to be transformed\n",
        "#     mean: mean value of data\n",
        "#     max_v: max value of data\n",
        "#     :return\n",
        "#     The normalized data\n",
        "#     \"\"\"\n",
        "# #     std =np.std(data)\n",
        "# #     mean = data.mean()\n",
        "# #     max_v = data.max()\n",
        "\n",
        "#     return data/4505.783 #remember to try this normalization as well\n",
        "#     #return (data - mean) / (max_v-mean)\n",
        "\n",
        "\n",
        "# def inversenormalise(data):\n",
        "#     \"\"\"\n",
        "#     Perform the in-normalisation data*(max(x)-min(x))+min(x).\n",
        "#     ------------------------------------------------\n",
        "#     :arg\n",
        "#     data: data that needs to be inverse-transformed\n",
        "#     mean: mean value of data\n",
        "#     max_v: max value of data\n",
        "#     :return\n",
        "#     The in-normalized data\n",
        "#     \"\"\"\n",
        "# #     std =np.std(data)\n",
        "# #     mean = data.mean()\n",
        "# #     max_v = data.max()\n",
        "    \n",
        "#     return data * 4505.783\n",
        "\n",
        "    #return data * (max_v-mean) + mean\n",
        "\n",
        "# def standardise(X, how='std=1', mean=None, std=None, midrange=None,\n",
        "#                 ptp=None):\n",
        "#     \"\"\"Standardise.\n",
        "#     ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std_in\n",
        "#     Parameters\n",
        "#     ----------\n",
        "#     X : matrix\n",
        "#         Each sample is in range [0, 1]\n",
        "#     how : str, {'range=2', 'std=1'}\n",
        "#         'range=2' sets midrange to 0 and enforces\n",
        "#         all values to be in the range [-1,1]\n",
        "#         'std=1' sets mean = 0 and std = 1\n",
        "#     Returns\n",
        "#     -------\n",
        "#     new_X : matrix\n",
        "#         Same shape as `X`.  Sample is in range [lower, upper]\n",
        "#     See also\n",
        "#     --------\n",
        "#     unstandardise\n",
        "#     \"\"\"\n",
        "#     if how == 'std=1':\n",
        "#         if mean is None:\n",
        "#             mean = X.mean()\n",
        "#         if std is None:\n",
        "#             std = X.std()\n",
        "#         centered = X - mean\n",
        "#         if std == 0:\n",
        "#             return centered\n",
        "#         else:\n",
        "#             return centered / std\n",
        "#     elif how == 'range=2':\n",
        "#         if midrange is None:\n",
        "#             midrange = (X.max() + X.min()) / 2\n",
        "#         if ptp is None:\n",
        "#             ptp = X.ptp()\n",
        "#         return (X - midrange) / (ptp / 2)\n",
        "#     else:\n",
        "#         raise RuntimeError(\"unrecognised how '\" + how + \"'\")\n",
        "        \n",
        "# def unstandardise(data, std=None, mean=None, maximum=None):\n",
        "#     unstandardised_data = (data * std) + mean\n",
        "#     if maximum is not None:\n",
        "#         unstandardised_data *= maximum\n",
        "#     return unstandardised_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJhwpBs3muoz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data_normalization():\n",
        "  \n",
        "  \n",
        "  def __init__(self, mean=None, std=None, maxx=None):\n",
        "        '''Initialize \n",
        "        '''\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "        self.mean2 = mean\n",
        "        self.std2 = std\n",
        "        self.max = maxx\n",
        "        \n",
        "  def normalise(self,data):\n",
        "    if self.max is None:\n",
        "      self.max = data.max()\n",
        "    return data/self.max\n",
        "  \n",
        "  def inversenormalise(self,data):\n",
        "    \n",
        "    return data*self.max\n",
        "\n",
        "\n",
        "  def standardise(self,X, how='std=1', midrange=None,\n",
        "                  ptp=None):\n",
        "      \"\"\"Standardise.\n",
        "      ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std_in\n",
        "      Parameters\n",
        "      ----------\n",
        "      X : matrix\n",
        "          Each sample is in range [0, 1]\n",
        "      how : str, {'range=2', 'std=1'}\n",
        "          'range=2' sets midrange to 0 and enforces\n",
        "          all values to be in the range [-1,1]\n",
        "          'std=1' sets mean = 0 and std = 1\n",
        "      Returns\n",
        "      -------\n",
        "      new_X : matrix\n",
        "          Same shape as `X`.  Sample is in range [lower, upper]\n",
        "      See also\n",
        "      --------\n",
        "      unstandardise\n",
        "      \"\"\"\n",
        "      if how == 'std=1':\n",
        "          if self.mean is None:\n",
        "              self.mean = X.mean()\n",
        "          if self.std is None:\n",
        "              self.std = X.std()\n",
        "          centered = X - self.mean\n",
        "          if self.std == 0:\n",
        "              return centered\n",
        "          else:\n",
        "              return centered / self.std\n",
        "      elif how == 'range=2':\n",
        "          if midrange is None:\n",
        "              midrange = (X.max() + X.min()) / 2\n",
        "          if ptp is None:\n",
        "              ptp = X.ptp()\n",
        "          return (X - midrange) / (ptp / 2)\n",
        "      else:\n",
        "          raise RuntimeError(\"unrecognised how '\" + how + \"'\")\n",
        "\n",
        "  def unstandardise(self, data, maximum=None):\n",
        "      unstandardised_data = (data * self.std) + self.mean\n",
        "      if maximum is not None:\n",
        "          unstandardised_data *= maximum\n",
        "      return unstandardised_data\n",
        "    \n",
        "  def standardise2(self,X, how='std=1', midrange=None,\n",
        "                  ptp=None):\n",
        "      \"\"\"Standardise.\n",
        "      ftp://ftp.sas.com/pub/neural/FAQ2.html#A_std_in\n",
        "      Parameters\n",
        "      ----------\n",
        "      X : matrix\n",
        "          Each sample is in range [0, 1]\n",
        "      how : str, {'range=2', 'std=1'}\n",
        "          'range=2' sets midrange to 0 and enforces\n",
        "          all values to be in the range [-1,1]\n",
        "          'std=1' sets mean = 0 and std = 1\n",
        "      Returns\n",
        "      -------\n",
        "      new_X : matrix\n",
        "          Same shape as `X`.  Sample is in range [lower, upper]\n",
        "      See also\n",
        "      --------\n",
        "      unstandardise\n",
        "      \"\"\"\n",
        "      if how == 'std=1':\n",
        "          if self.mean2 is None:\n",
        "              self.mean2 = X.mean()\n",
        "          if self.std2 is None:\n",
        "              self.std2 = X.std()\n",
        "          centered = X - self.mean2\n",
        "          if self.std2 == 0:\n",
        "              return centered\n",
        "          else:\n",
        "              return centered / self.std2\n",
        "      elif how == 'range=2':\n",
        "          if midrange is None:\n",
        "              midrange = (X.max() + X.min()) / 2\n",
        "          if ptp is None:\n",
        "              ptp = X.ptp()\n",
        "          return (X - midrange) / (ptp / 2)\n",
        "      else:\n",
        "          raise RuntimeError(\"unrecognised how '\" + how + \"'\")\n",
        "          \n",
        "  def unstandardise2(self, data, maximum=None):\n",
        "      unstandardised_data = (data * self.std2) + self.mean2\n",
        "      if maximum is not None:\n",
        "          unstandardised_data *= maximum\n",
        "      return unstandardised_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPNy3dv4y24k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model, Model, Input\n",
        "from keras.layers import Dense, Conv1D, GRU, LSTM, Bidirectional, Dropout,Conv2D\n",
        "from keras.layers import Reshape, BatchNormalization, Activation, Flatten, Concatenate\n",
        "from keras.models import Sequential\n",
        "\n",
        "def RNN_model(window_size):\n",
        "    '''Creates the RNN module described in the paper\n",
        "    '''\n",
        "    model = Sequential()\n",
        "\n",
        "    # 1D Conv\n",
        "    model.add(Conv1D(16, 4, activation=\"linear\", input_shape=(window_size,1), padding=\"same\", strides=1))\n",
        "\n",
        "    #Bi-directional LSTMs\n",
        "    model.add(Bidirectional(LSTM(128, return_sequences=True, stateful=False), merge_mode='concat'))\n",
        "    model.add(Bidirectional(LSTM(256, return_sequences=False, stateful=False), merge_mode='concat'))\n",
        "\n",
        "    # Fully Connected Layers\n",
        "    model.add(Dense(128, activation='tanh'))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    #plot_model(model, to_file='model.png', show_shapes=True)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def GRU_model(window_size):\n",
        "\n",
        "    '''Creates the GRU architecture described in the paper\n",
        "    '''\n",
        "    model = Sequential()\n",
        "\n",
        "    # 1D Conv\n",
        "    model.add(Conv1D(16, 4, activation=\"relu\", padding=\"same\", strides=1, input_shape=(params['window_size'],1)))\n",
        "    model.add(Conv1D(8, 4, activation=\"relu\", padding=\"same\", strides=1))\n",
        "\n",
        "    # Bi-directional LSTMs\n",
        "    model.add(Bidirectional(GRU(128, return_sequences=True, stateful=False), merge_mode='concat'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Bidirectional(GRU(256, return_sequences=False, stateful=False), merge_mode='concat'))\n",
        "    model.add(Dropout(0.3))\n",
        "    # Fully Connected Layers\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def DAE_model(window_size):\n",
        "    '''Creates and returns the ShortSeq2Point Network\n",
        "     Based on: https://arxiv.org/pdf/1612.09106v3.pdf\n",
        "    '''\n",
        "    model = Sequential()\n",
        "\n",
        "    # 1D Conv\n",
        "    model.add(Conv1D(30, 10, activation='relu', input_shape=(window_size,1), padding=\"same\", strides=1))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(30, 8, activation='relu', padding=\"same\", strides=1))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(40, 6, activation='relu', padding=\"same\", strides=1))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(50, 5, activation='relu', padding=\"same\", strides=1))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv1D(50, 5, activation='relu', padding=\"same\", strides=1))\n",
        "    model.add(Dropout(0.2))\n",
        "    # Fully Connected Layers\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n",
        "\n",
        "def DresNET_model(window_size):\n",
        "    '''Creates the GRU architecture described in the paper\n",
        "    '''\n",
        "    def residual_block(filters,x,stride = 1,dilate = None):\n",
        "        resiual = x\n",
        "        out = BatchNormalization()(x)\n",
        "        out1 = Activation('relu')(out)\n",
        "        out = Conv1D(filters = filters,kernel_size = [3],dilation_rate = dilate,strides = [1],padding = 'same')(out1)\n",
        "        out = BatchNormalization()(out)\n",
        "        out = Activation('relu')(out)\n",
        "        out = Conv1D(filters = filters,kernel_size = [3],strides = [1],padding = 'same')(out)\n",
        "        out = BatchNormalization()(out)\n",
        "        out = Activation('relu')(out)\n",
        "        out = Conv1D(filters = filters,kernel_size = [1],dilation_rate = dilate,strides = [1],padding = 'same')(out)\n",
        "\n",
        "        if out1.shape[-1] != filters or stride == 1:\n",
        "            residual = Conv1D(filters = filters,kernel_size = [3],strides = [1],padding = 'same')(out1)\n",
        "            out = Concatenate()([residual,out])\n",
        "        return out\n",
        "\n",
        "    x = Input(shape = [window_size,1])\n",
        "    conv1 = Conv1D(filters = 30,kernel_size = [5],dilation_rate = [1],strides = [1],padding = 'same')(x)\n",
        "    bn = BatchNormalization()(conv1)\n",
        "    out = Activation('relu')(bn)\n",
        "    repetition = [3,4,6,3]\n",
        "    filter_num = [30,40,50,50]\n",
        "    dilations = [[1],[2],[3],[3]]\n",
        "    for i in range(len(repetition)):\n",
        "        for j in range(repetition[i]):\n",
        "            out = residual_block(filters = filter_num[i],dilate = dilations[i],x = out)\n",
        "\n",
        "    out = Flatten()(out)\n",
        "    out = Dense(units = 1)(out)\n",
        "    model = Model(x,out)\n",
        "    model.compile(optimizer = 'adam',loss = 'mse')\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHJPt__pyuMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from warnings import warn, filterwarnings\n",
        "\n",
        "import random\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from nilmtk.disaggregate import Disaggregator\n",
        "from nilmtk.datastore import HDFDataStore\n",
        "\n",
        "\n",
        "\n",
        "class NeuralDisaggregator(Disaggregator):\n",
        "    '''Attempt to create a RNN Disaggregator\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    model : keras Sequential model\n",
        "    mmax : the maximum value of the aggregate data\n",
        "\n",
        "    MIN_CHUNK_LENGTH : int\n",
        "       the minimum length of an acceptable chunk\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, model, name, batch_size, norm, window_size=100):\n",
        "        '''Initialize disaggregator\n",
        "        '''\n",
        "        self.MODEL_NAME = name\n",
        "        self.MIN_CHUNK_LENGTH = window_size\n",
        "        self.window_size = window_size\n",
        "        self.model = model\n",
        "        self.batch_size = batch_size\n",
        "        self.norm = norm\n",
        "            \n",
        "    def disaggregate(self, mains, output_datastore, meter_metadata, **load_kwargs):\n",
        "        '''Disaggregate mains according to the model learnt previously.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mains : a nilmtk.ElecMeter of aggregate data\n",
        "        meter_metadata: a nilmtk.ElecMeter of the observed meter used for storing the metadata\n",
        "        output_datastore : instance of nilmtk.DataStore subclass\n",
        "            For storing power predictions from disaggregation algorithm.\n",
        "        **load_kwargs : key word arguments\n",
        "            Passed to `mains.power_series(**kwargs)`\n",
        "        '''\n",
        "\n",
        "        load_kwargs = self._pre_disaggregation_checks(load_kwargs)\n",
        "\n",
        "        load_kwargs.setdefault('sample_period', 60)\n",
        "        load_kwargs.setdefault('sections', mains.good_sections())\n",
        "\n",
        "        timeframes = []\n",
        "        building_path = '/building{}'.format(mains.building())\n",
        "        mains_data_location = building_path + '/elec/meter1'\n",
        "        data_is_available = False\n",
        "\n",
        "        for chunk in mains.power_series(**load_kwargs):\n",
        "            if len(chunk) < self.MIN_CHUNK_LENGTH:\n",
        "                continue\n",
        "            print(\"New sensible chunk: {}\".format(len(chunk)))\n",
        "\n",
        "            timeframes.append(chunk.timeframe)\n",
        "            measurement = chunk.name\n",
        "            chunk2 = norm.standardise(chunk)\n",
        "            #chunk2=chunk\n",
        "            appliance_power = self.disaggregate_chunk(chunk2)\n",
        "            appliance_power[appliance_power < 0] = 0\n",
        "            appliance_power = norm.unstandardise2(appliance_power)\n",
        "\n",
        "            # Append prediction to output\n",
        "            data_is_available = True\n",
        "            cols = pd.MultiIndex.from_tuples([chunk.name])\n",
        "            meter_instance = meter_metadata.instance()\n",
        "            df = pd.DataFrame(\n",
        "                appliance_power.values, index=appliance_power.index,\n",
        "                columns=cols, dtype=\"float32\")\n",
        "            key = '{}/elec/meter{}'.format(building_path, meter_instance)\n",
        "            output_datastore.append(key, df)\n",
        "\n",
        "            # Append aggregate data to output\n",
        "            mains_df = pd.DataFrame(chunk, columns=cols, dtype=\"float32\")\n",
        "            output_datastore.append(key=mains_data_location, value=mains_df)\n",
        "\n",
        "        # Save metadata to output\n",
        "        if data_is_available:\n",
        "            self._save_metadata_for_disaggregation(\n",
        "                output_datastore=output_datastore,\n",
        "                sample_period=load_kwargs['sample_period'],\n",
        "                measurement=measurement,\n",
        "                timeframes=timeframes,\n",
        "                building=mains.building(),\n",
        "                meters=[meter_metadata]\n",
        "            )\n",
        "\n",
        "    def disaggregate_chunk(self, mains):\n",
        "        '''In-memory disaggregation.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        mains : pd.Series of aggregate data\n",
        "        Returns\n",
        "        -------\n",
        "        appliance_powers : pd.DataFrame where each column represents a\n",
        "            disaggregated appliance.  Column names are the integer index\n",
        "            into `self.model` for the appliance in question.\n",
        "        '''\n",
        "        up_limit = len(mains)\n",
        "\n",
        "        mains.fillna(0, inplace=True)\n",
        "\n",
        "        X_batch = np.array(mains)\n",
        "        Y_len = len(X_batch)\n",
        "        indexer = np.arange(self.window_size)[None, :] + np.arange(len(X_batch)-self.window_size+1)[:, None]\n",
        "        X_batch = X_batch[indexer]\n",
        "        X_batch = np.reshape(X_batch, (X_batch.shape[0],X_batch.shape[1],1))\n",
        "\n",
        "        pred = self.model.predict(X_batch, batch_size=self.batch_size)\n",
        "        pred = np.reshape(pred, (len(pred)))\n",
        "        column = pd.Series(pred, index=mains.index[self.window_size-1:Y_len], name=0)\n",
        "        \n",
        "\n",
        "        appliance_powers_dict = {}\n",
        "        appliance_powers_dict[0] = column\n",
        "        appliance_powers = pd.DataFrame(appliance_powers_dict)\n",
        "        return appliance_powers\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUFVTW1ayl_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from nilmtk.electric import align_two_meters\n",
        "import numpy as np\n",
        "\n",
        "def tp_tn_fp_fn(states_pred, states_ground):\n",
        "    tp = np.sum(np.logical_and(states_pred == 1, states_ground == 1))\n",
        "    fp = np.sum(np.logical_and(states_pred == 1, states_ground == 0))\n",
        "    fn = np.sum(np.logical_and(states_pred == 0, states_ground == 1))\n",
        "    tn = np.sum(np.logical_and(states_pred == 0, states_ground == 0))\n",
        "    return tp, tn, fp, fn\n",
        "\n",
        "def recall_precision_accuracy_f1(pred, ground):\n",
        "    aligned_meters = align_two_meters(pred, ground)\n",
        "    threshold = ground.on_power_threshold()\n",
        "    chunk_results = []\n",
        "    sum_samples = 0.0\n",
        "    for chunk in aligned_meters:\n",
        "        sum_samples += len(chunk)\n",
        "        pr = np.array([0 if (p)<threshold else 1 for p in chunk.iloc[:,0]])\n",
        "        gr = np.array([0 if p<threshold else 1 for p in chunk.iloc[:,1]])\n",
        "\n",
        "        tp, tn, fp, fn = tp_tn_fp_fn(pr,gr)\n",
        "        p = sum(pr)\n",
        "        n = len(pr) - p\n",
        "\n",
        "        chunk_results.append([tp,tn,fp,fn,p,n])\n",
        "\n",
        "    if sum_samples == 0:\n",
        "        return None\n",
        "    else:\n",
        "        [tp,tn,fp,fn,p,n] = np.sum(chunk_results, axis=0)\n",
        "\n",
        "        res_recall = recall(tp,fn)\n",
        "        res_precision = precision(tp,fp)\n",
        "        res_f1 = f1(res_precision,res_recall)\n",
        "        res_accuracy = accuracy(tp,tn,p,n)\n",
        "\n",
        "        return (res_recall,res_precision,res_accuracy,res_f1)\n",
        "\n",
        "def relative_error_total_energy(pred, ground):\n",
        "    aligned_meters = align_two_meters(pred, ground)\n",
        "    chunk_results = []\n",
        "    sum_samples = 0.0\n",
        "    for chunk in aligned_meters:\n",
        "        chunk.fillna(0, inplace=True)\n",
        "        sum_samples += len(chunk)\n",
        "        E_pred = sum(chunk.iloc[:,0])\n",
        "        E_ground = sum(chunk.iloc[:,1])\n",
        "\n",
        "        chunk_results.append([\n",
        "                            E_pred,\n",
        "                            E_ground\n",
        "                            ])\n",
        "    if sum_samples == 0:\n",
        "        return None\n",
        "    else:\n",
        "        [E_pred, E_ground] = np.sum(chunk_results,axis=0)\n",
        "        return abs(E_pred - E_ground) / float(max(E_pred,E_ground))\n",
        "\n",
        "def mean_absolute_error(pred, ground):\n",
        "    aligned_meters = align_two_meters(pred, ground)\n",
        "    total_sum = 0.0\n",
        "    sum_samples = 0.0\n",
        "    for chunk in aligned_meters:\n",
        "        chunk.fillna(0, inplace=True)\n",
        "        sum_samples += len(chunk)\n",
        "        total_sum += sum(abs((chunk.iloc[:,0]) - chunk.iloc[:,1]))\n",
        "    if sum_samples == 0:\n",
        "        return None\n",
        "    else:\n",
        "        return total_sum / sum_samples\n",
        "\n",
        "\n",
        "def recall(tp,fn):\n",
        "    return tp/float(tp+fn)\n",
        "\n",
        "def precision(tp,fp):\n",
        "    return tp/float(tp+fp)\n",
        "\n",
        "def f1(prec,rec):\n",
        "    return 2 * (prec*rec) / float(prec+rec)\n",
        "\n",
        "def accuracy(tp, tn, p, n):\n",
        "    return (tp + tn) / float(p + n)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8sgly5YyimH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class Batch_Generator():\n",
        "\n",
        "    def __init__(self, batch_size, window_size, model_name, shuffle=True):\n",
        "\n",
        "        self.name = model_name\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.window_size = window_size\n",
        "        \n",
        "    def num_epochs(self, inputs):\n",
        "        \n",
        "        batch_size = int(self.batch_size / len(inputs))\n",
        "        num_of_batches = [(int((len(inputs[i])-self.window_size+1) / batch_size) - 1) for i in range(len(inputs))]\n",
        "        n_epochs = min(num_of_batches)\n",
        "        \n",
        "        return n_epochs\n",
        "\n",
        "    def generator(self, inputs, targets):\n",
        "      \n",
        "        num_meters = len(inputs)\n",
        "        batch_size = int(self.batch_size / num_meters)\n",
        "        #num_of_batches = [(int(len(inputs[i]) / batch_size) - 1) for i in range(len(inputs))]\n",
        "\n",
        "        n_epochs = self.num_epochs(inputs)\n",
        "\n",
        "\n",
        "        # Batch indexes\n",
        "        while True:\n",
        "          self.indexes = list(range(n_epochs))\n",
        "\n",
        "          if self.shuffle == True:\n",
        "              np.random.shuffle(self.indexes)\n",
        "\n",
        "          for ei, e in enumerate(self.indexes):\n",
        "\n",
        "              offset = e * batch_size\n",
        "\n",
        "              # Initialization\n",
        "              X_batch = np.zeros((batch_size * num_meters, self.window_size, 1))  # (128,100,1)\n",
        "              Y_batch = np.zeros((batch_size * num_meters, 1))  # (128,1)\n",
        "\n",
        "              # Create a batch out of data from all buildings\n",
        "              for i in range(num_meters):\n",
        "                  mainpart = inputs[i]\n",
        "                  meterpart = targets[i]\n",
        "\n",
        "                  indexer = np.arange(self.window_size)[None, :] + np.arange(len(inputs[i])-self.window_size+1)[offset:offset + batch_size, None]\n",
        "\n",
        "                  mainpart = mainpart[indexer]\n",
        "                  meterpart = meterpart[self.window_size - 1:][offset:offset + batch_size]\n",
        "\n",
        "                  X = np.reshape(mainpart, (batch_size, self.window_size, 1))\n",
        "                  Y = np.reshape(meterpart, (batch_size, 1))\n",
        "\n",
        "                  X_batch[i * batch_size:(i + 1) * batch_size] = np.array(X)\n",
        "                  Y_batch[i * batch_size:(i + 1) * batch_size] = np.array(Y)\n",
        "                  \n",
        "              \n",
        "\n",
        "#               # Shuffle data\n",
        "#               if self.shuffle == True:\n",
        "#                 p = np.random.permutation(len(X_batch))\n",
        "#                 X_batch, Y_batch = X_batch[p], Y_batch[p]\n",
        "       \n",
        "              yield X_batch, Y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXmq80OAyVQD",
        "colab_type": "code",
        "outputId": "7b3a9ecc-d8db-4a03-944c-7371ef528583",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import time\n",
        "\n",
        "\n",
        "from matplotlib import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nilmtk import DataSet, TimeFrame, MeterGroup, HDFDataStore\n",
        "#from disaggregator import NeuralDisaggregator\n",
        "#from dataset_processing import load_dataset, data_processing\n",
        "#from batch_generator import Batch_Generator\n",
        "#from models import GRU_model, RNN_model, DAE_model, DresNET_model\n",
        "from keras.models import load_model\n",
        "import metrics\n",
        "#import nilm_metric as nm\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# =====Define paramaters======\n",
        "info = {'filename': 'drive/My Drive/Dissertation/ukdale.h5',\n",
        "        'meter_label': 'kettle',  # [\"kettle\" , \"microwave\" , \"dishwasher\" , \"fridge\" , \"washing_machine\"]\n",
        "        'train_building': [1],\n",
        "        'test_building': 1,\n",
        "        'sample_period': 6\n",
        "       }\n",
        "\n",
        "# Parameters\n",
        "params = {'batch_size': 128,\n",
        "          'window_size': 100,\n",
        "          'model_name': 'DresNET',\n",
        "          'shuffle': True}\n",
        "\n",
        "#Define the training intervals for each house\n",
        "window_per_house = {1: ('2016-08-16', '2016-10-21'), \n",
        "                2: (\"2013-04-16\", \"2013-10-10\"), \n",
        "                3: ('2013-02-27' , '2013-04-08 '), \n",
        "                4: (\"2013-03-09\", \"2013-10-01\"), \n",
        "                5: (\"2014-06-29\", None)}\n",
        "\n",
        "\n",
        "test_window = {1: ('2016-10-21', '2016-10-30')}\n",
        "\n",
        "\n",
        "num_epochs = 5\n",
        "# =====Load Dataset======\n",
        "train_meterlist, train_mainlist, test_meterlist, test_mainlist = load_dataset(window_per_house,test_window, **info)\n",
        "\n",
        "train_x, train_y, norm = data_processing(train_mainlist, train_meterlist, window_size=params['window_size'])\n",
        "\n",
        "\n",
        "\n",
        "if params['model_name'] == 'LSTM':\n",
        "    model = RNN_model(params['window_size'])\n",
        "\n",
        "elif params['model_name'] == 'GRU':\n",
        "    model = GRU_model(params['window_size'])\n",
        "\n",
        "elif params['model_name'] == 'DAE':\n",
        "    model = DAE_model(params['window_size'])\n",
        "\n",
        "elif params['model_name'] == 'DresNET':\n",
        "    model = DresNET_model(params['window_size'])\n",
        "\n",
        "\n",
        "\n",
        "# Training\n",
        "filepath_checkpoint = \"UKDALE-RNN-h \" + str(info['train_building']) + str(info['meter_label']) + ' epo.hdf5'\n",
        "filepath = 'drive/My Drive/Dissertation/UKDALE-GRU-microwave-5epochs.h5'\n",
        "filepath = 'UKDALE-GRU-fridge-8epochs.h5'\n",
        "\n",
        "# Batch generator\n",
        "gen = Batch_Generator(**params)\n",
        "t = gen.generator(train_x, train_y)\n",
        "steps_epochs = gen.num_epochs(train_x)\n",
        "\n",
        "\n",
        "\n",
        "mode = 'training'\n",
        "\n",
        "if mode == 'training':\n",
        "\n",
        "    print(\"*********Training*********\")\n",
        "    start = time.time()\n",
        "    indexer = np.arange(params['window_size'])[None, :] + np.arange(len(train_x[0])-params['window_size']+1)[:, None]\n",
        "    x = train_x[0][indexer]\n",
        "    y = train_y[0][params['window_size']-1:]\n",
        "\n",
        "    x = np.reshape(x, (x.shape[0],params['window_size'],1))\n",
        "    y = np.reshape(y, (y.shape[0],1))\n",
        "    model.fit(x, y, epochs=num_epochs, batch_size=128, shuffle=True)\n",
        "\n",
        "#     checkpointer = ModelCheckpoint(filepath_checkpoint,\n",
        "#                                    verbose=1, save_best_only=True)\n",
        "#     model.fit_generator(t, \n",
        "#                         steps_per_epoch = steps_epochs, \n",
        "#                         epochs=num_epochs,\n",
        "#                         use_multiprocessing=True,\n",
        "#                         workers=6, \n",
        "#                         callbacks=[checkpointer])\n",
        "\n",
        "    \n",
        "    \n",
        "    model.save(\"UKDALE-{}-{}-{}epochs.h5\".format(params['model_name'], \n",
        "                                                     info['meter_label'],\n",
        "                                                      num_epochs))\n",
        "    \n",
        "    end = time.time()\n",
        "    print('### Total trainning time cost: {} ###'.format(str(end - start)))\n",
        "\n",
        "elif mode == 'loading':\n",
        "    # load checkpoints weights\n",
        "    print(filepath_checkpoint)\n",
        "    model.load_weights(filepath_checkpoint)\n",
        "    \n",
        "elif mode == 'load_pretrained':\n",
        "    #load pretrained model\n",
        "    model = load_model(filepath)\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "     \n",
        "    \n",
        "# print(\"*********Disaggregate*********\")\n",
        "disaggregator = NeuralDisaggregator(model, name = params['model_name'],batch_size = params['batch_size'],norm = norm, window_size = params['window_size'])\n",
        "disag_filename = \"disag-out4.h5\"\n",
        "output = HDFDataStore(disag_filename, 'w')\n",
        "disaggregator.disaggregate(test_mainlist, output, test_meterlist, sample_period = info['sample_period'])\n",
        "output.close()\n",
        "\n",
        "\n",
        "print(\"========== RESULTS ============\")\n",
        "meter_key = info['meter_label']\n",
        "result = DataSet(disag_filename)\n",
        "res_elec = result.buildings[info['test_building']].elec\n",
        "#print(test_meterlist.power_series_all_data())\n",
        "#print(res_elec[meter_key].power_series_all_data())\n",
        "rpaf = metrics.recall_precision_accuracy_f1(res_elec[meter_key], test_meterlist)\n",
        "print(\"============ Recall: {}\".format(rpaf[0]))\n",
        "print(\"============ Precision: {}\".format(rpaf[1]))\n",
        "print(\"============ Accuracy: {}\".format(rpaf[2]))\n",
        "print(\"============ F1 Score: {}\".format(rpaf[3]))\n",
        "\n",
        "print(\"============ Relative error in total energy: {}\".format(metrics.relative_error_total_energy(res_elec[meter_key], test_meterlist)))\n",
        "print(\"============ Mean absolute error(in Watts): {}\".format(metrics.mean_absolute_error(res_elec[meter_key], test_meterlist)))\n",
        "\n",
        "\n",
        "# aligned_meters = align_two_meters(res_elec[meter_key], test_meterlist)\n",
        "# #threshold = ground.on_power_threshold()\n",
        "# meters = next(aligned_meters)\n",
        "# threshold = 10\n",
        "# predict = meters['master']\n",
        "# ground = meters['slave']\n",
        "# print()\n",
        "# print('F1:{0}'.format(nm.get_F1(ground, predict, threshold)))\n",
        "# print('Mean absolute error(in Watts):{0}'.format(nm.get_abs_error(ground, predict)))\n",
        "# print('Relative error:{0}'.format(nm.get_relative_error(ground, predict)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nilmtk/utils.py:507: UserWarning: Found duplicate index. Keeping first value\n",
            "  warnings.warn(\"Found duplicate index. Keeping first value\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 100, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_131 (Conv1D)             (None, 100, 30)      180         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 100, 30)      120         conv1d_131[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_99 (Activation)      (None, 100, 30)      0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 100, 30)      120         activation_99[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_100 (Activation)     (None, 100, 30)      0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_132 (Conv1D)             (None, 100, 30)      2730        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 100, 30)      120         conv1d_132[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_101 (Activation)     (None, 100, 30)      0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_133 (Conv1D)             (None, 100, 30)      2730        activation_101[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 100, 30)      120         conv1d_133[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_102 (Activation)     (None, 100, 30)      0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_135 (Conv1D)             (None, 100, 30)      2730        activation_100[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_134 (Conv1D)             (None, 100, 30)      930         activation_102[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_33 (Concatenate)    (None, 100, 60)      0           conv1d_135[0][0]                 \n",
            "                                                                 conv1d_134[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 100, 60)      240         concatenate_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_103 (Activation)     (None, 100, 60)      0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_136 (Conv1D)             (None, 100, 30)      5430        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 100, 30)      120         conv1d_136[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_104 (Activation)     (None, 100, 30)      0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_137 (Conv1D)             (None, 100, 30)      2730        activation_104[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 100, 30)      120         conv1d_137[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_105 (Activation)     (None, 100, 30)      0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_139 (Conv1D)             (None, 100, 30)      5430        activation_103[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_138 (Conv1D)             (None, 100, 30)      930         activation_105[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 100, 60)      0           conv1d_139[0][0]                 \n",
            "                                                                 conv1d_138[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 100, 60)      240         concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_106 (Activation)     (None, 100, 60)      0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_140 (Conv1D)             (None, 100, 30)      5430        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 100, 30)      120         conv1d_140[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_107 (Activation)     (None, 100, 30)      0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_141 (Conv1D)             (None, 100, 30)      2730        activation_107[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 100, 30)      120         conv1d_141[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_108 (Activation)     (None, 100, 30)      0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_143 (Conv1D)             (None, 100, 30)      5430        activation_106[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_142 (Conv1D)             (None, 100, 30)      930         activation_108[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 100, 60)      0           conv1d_143[0][0]                 \n",
            "                                                                 conv1d_142[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_109 (BatchN (None, 100, 60)      240         concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_109 (Activation)     (None, 100, 60)      0           batch_normalization_109[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_144 (Conv1D)             (None, 100, 40)      7240        activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_110 (BatchN (None, 100, 40)      160         conv1d_144[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_110 (Activation)     (None, 100, 40)      0           batch_normalization_110[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_145 (Conv1D)             (None, 100, 40)      4840        activation_110[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_111 (BatchN (None, 100, 40)      160         conv1d_145[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_111 (Activation)     (None, 100, 40)      0           batch_normalization_111[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_147 (Conv1D)             (None, 100, 40)      7240        activation_109[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_146 (Conv1D)             (None, 100, 40)      1640        activation_111[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 100, 80)      0           conv1d_147[0][0]                 \n",
            "                                                                 conv1d_146[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_112 (BatchN (None, 100, 80)      320         concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_112 (Activation)     (None, 100, 80)      0           batch_normalization_112[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_148 (Conv1D)             (None, 100, 40)      9640        activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_113 (BatchN (None, 100, 40)      160         conv1d_148[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_113 (Activation)     (None, 100, 40)      0           batch_normalization_113[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_149 (Conv1D)             (None, 100, 40)      4840        activation_113[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_114 (BatchN (None, 100, 40)      160         conv1d_149[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_114 (Activation)     (None, 100, 40)      0           batch_normalization_114[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_151 (Conv1D)             (None, 100, 40)      9640        activation_112[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_150 (Conv1D)             (None, 100, 40)      1640        activation_114[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 100, 80)      0           conv1d_151[0][0]                 \n",
            "                                                                 conv1d_150[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_115 (BatchN (None, 100, 80)      320         concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_115 (Activation)     (None, 100, 80)      0           batch_normalization_115[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_152 (Conv1D)             (None, 100, 40)      9640        activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_116 (BatchN (None, 100, 40)      160         conv1d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_116 (Activation)     (None, 100, 40)      0           batch_normalization_116[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_153 (Conv1D)             (None, 100, 40)      4840        activation_116[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_117 (BatchN (None, 100, 40)      160         conv1d_153[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_117 (Activation)     (None, 100, 40)      0           batch_normalization_117[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_155 (Conv1D)             (None, 100, 40)      9640        activation_115[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_154 (Conv1D)             (None, 100, 40)      1640        activation_117[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 100, 80)      0           conv1d_155[0][0]                 \n",
            "                                                                 conv1d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_118 (BatchN (None, 100, 80)      320         concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_118 (Activation)     (None, 100, 80)      0           batch_normalization_118[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_156 (Conv1D)             (None, 100, 40)      9640        activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_119 (BatchN (None, 100, 40)      160         conv1d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_119 (Activation)     (None, 100, 40)      0           batch_normalization_119[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_157 (Conv1D)             (None, 100, 40)      4840        activation_119[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_120 (BatchN (None, 100, 40)      160         conv1d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_120 (Activation)     (None, 100, 40)      0           batch_normalization_120[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_159 (Conv1D)             (None, 100, 40)      9640        activation_118[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_158 (Conv1D)             (None, 100, 40)      1640        activation_120[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 100, 80)      0           conv1d_159[0][0]                 \n",
            "                                                                 conv1d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_121 (BatchN (None, 100, 80)      320         concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_121 (Activation)     (None, 100, 80)      0           batch_normalization_121[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_160 (Conv1D)             (None, 100, 50)      12050       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_122 (BatchN (None, 100, 50)      200         conv1d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_122 (Activation)     (None, 100, 50)      0           batch_normalization_122[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_161 (Conv1D)             (None, 100, 50)      7550        activation_122[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_123 (BatchN (None, 100, 50)      200         conv1d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_123 (Activation)     (None, 100, 50)      0           batch_normalization_123[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_163 (Conv1D)             (None, 100, 50)      12050       activation_121[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_162 (Conv1D)             (None, 100, 50)      2550        activation_123[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 100, 100)     0           conv1d_163[0][0]                 \n",
            "                                                                 conv1d_162[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_124 (BatchN (None, 100, 100)     400         concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_124 (Activation)     (None, 100, 100)     0           batch_normalization_124[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_164 (Conv1D)             (None, 100, 50)      15050       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_125 (BatchN (None, 100, 50)      200         conv1d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_125 (Activation)     (None, 100, 50)      0           batch_normalization_125[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_165 (Conv1D)             (None, 100, 50)      7550        activation_125[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_126 (BatchN (None, 100, 50)      200         conv1d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_126 (Activation)     (None, 100, 50)      0           batch_normalization_126[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_167 (Conv1D)             (None, 100, 50)      15050       activation_124[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_166 (Conv1D)             (None, 100, 50)      2550        activation_126[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 100, 100)     0           conv1d_167[0][0]                 \n",
            "                                                                 conv1d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_127 (BatchN (None, 100, 100)     400         concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_127 (Activation)     (None, 100, 100)     0           batch_normalization_127[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_168 (Conv1D)             (None, 100, 50)      15050       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_128 (BatchN (None, 100, 50)      200         conv1d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_128 (Activation)     (None, 100, 50)      0           batch_normalization_128[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_169 (Conv1D)             (None, 100, 50)      7550        activation_128[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_129 (BatchN (None, 100, 50)      200         conv1d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_129 (Activation)     (None, 100, 50)      0           batch_normalization_129[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_171 (Conv1D)             (None, 100, 50)      15050       activation_127[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_170 (Conv1D)             (None, 100, 50)      2550        activation_129[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_42 (Concatenate)    (None, 100, 100)     0           conv1d_171[0][0]                 \n",
            "                                                                 conv1d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_130 (BatchN (None, 100, 100)     400         concatenate_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_130 (Activation)     (None, 100, 100)     0           batch_normalization_130[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_172 (Conv1D)             (None, 100, 50)      15050       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_131 (BatchN (None, 100, 50)      200         conv1d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_131 (Activation)     (None, 100, 50)      0           batch_normalization_131[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_173 (Conv1D)             (None, 100, 50)      7550        activation_131[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_132 (BatchN (None, 100, 50)      200         conv1d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_132 (Activation)     (None, 100, 50)      0           batch_normalization_132[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_175 (Conv1D)             (None, 100, 50)      15050       activation_130[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_174 (Conv1D)             (None, 100, 50)      2550        activation_132[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_43 (Concatenate)    (None, 100, 100)     0           conv1d_175[0][0]                 \n",
            "                                                                 conv1d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_133 (BatchN (None, 100, 100)     400         concatenate_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_133 (Activation)     (None, 100, 100)     0           batch_normalization_133[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_176 (Conv1D)             (None, 100, 50)      15050       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_134 (BatchN (None, 100, 50)      200         conv1d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_134 (Activation)     (None, 100, 50)      0           batch_normalization_134[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_177 (Conv1D)             (None, 100, 50)      7550        activation_134[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_135 (BatchN (None, 100, 50)      200         conv1d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_135 (Activation)     (None, 100, 50)      0           batch_normalization_135[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_179 (Conv1D)             (None, 100, 50)      15050       activation_133[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_178 (Conv1D)             (None, 100, 50)      2550        activation_135[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_44 (Concatenate)    (None, 100, 100)     0           conv1d_179[0][0]                 \n",
            "                                                                 conv1d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 100, 100)     400         concatenate_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 100, 100)     0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_180 (Conv1D)             (None, 100, 50)      15050       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 100, 50)      200         conv1d_180[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 100, 50)      0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_181 (Conv1D)             (None, 100, 50)      7550        activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 100, 50)      200         conv1d_181[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 100, 50)      0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_183 (Conv1D)             (None, 100, 50)      15050       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_182 (Conv1D)             (None, 100, 50)      2550        activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_45 (Concatenate)    (None, 100, 100)     0           conv1d_183[0][0]                 \n",
            "                                                                 conv1d_182[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 100, 100)     400         concatenate_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 100, 100)     0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_184 (Conv1D)             (None, 100, 50)      15050       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 100, 50)      200         conv1d_184[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 100, 50)      0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_185 (Conv1D)             (None, 100, 50)      7550        activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 100, 50)      200         conv1d_185[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 100, 50)      0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_187 (Conv1D)             (None, 100, 50)      15050       activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_186 (Conv1D)             (None, 100, 50)      2550        activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_46 (Concatenate)    (None, 100, 100)     0           conv1d_187[0][0]                 \n",
            "                                                                 conv1d_186[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 100, 100)     400         concatenate_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 100, 100)     0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_188 (Conv1D)             (None, 100, 50)      15050       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 100, 50)      200         conv1d_188[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 100, 50)      0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_189 (Conv1D)             (None, 100, 50)      7550        activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 100, 50)      200         conv1d_189[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 100, 50)      0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_191 (Conv1D)             (None, 100, 50)      15050       activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_190 (Conv1D)             (None, 100, 50)      2550        activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_47 (Concatenate)    (None, 100, 100)     0           conv1d_191[0][0]                 \n",
            "                                                                 conv1d_190[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 100, 100)     400         concatenate_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 100, 100)     0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_192 (Conv1D)             (None, 100, 50)      15050       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 100, 50)      200         conv1d_192[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 100, 50)      0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_193 (Conv1D)             (None, 100, 50)      7550        activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 100, 50)      200         conv1d_193[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 100, 50)      0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_195 (Conv1D)             (None, 100, 50)      15050       activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_194 (Conv1D)             (None, 100, 50)      2550        activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_48 (Concatenate)    (None, 100, 100)     0           conv1d_195[0][0]                 \n",
            "                                                                 conv1d_194[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 10000)        0           concatenate_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            10001       flatten_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 513,421\n",
            "Trainable params: 507,901\n",
            "Non-trainable params: 5,520\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "*********Training*********\n",
            "Epoch 1/5\n",
            "950300/950300 [==============================] - 792s 833us/step - loss: 0.5742\n",
            "Epoch 2/5\n",
            "950300/950300 [==============================] - 754s 793us/step - loss: 0.4640\n",
            "Epoch 3/5\n",
            "950300/950300 [==============================] - 771s 812us/step - loss: 0.3247\n",
            "Epoch 4/5\n",
            "950300/950300 [==============================] - 787s 828us/step - loss: 0.2666\n",
            "Epoch 5/5\n",
            "950300/950300 [==============================] - 795s 837us/step - loss: 0.2188\n",
            "### Total trainning time cost: 4016.042047023773 ###\n",
            "New sensible chunk: 4680\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nilmtk/utils.py:507: UserWarning: Found duplicate index. Keeping first value\n",
            "  warnings.warn(\"Found duplicate index. Keeping first value\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "New sensible chunk: 14174\n",
            "New sensible chunk: 128\n",
            "New sensible chunk: 28607\n",
            "New sensible chunk: 200\n",
            "New sensible chunk: 14117\n",
            "New sensible chunk: 115\n",
            "New sensible chunk: 129\n",
            "New sensible chunk: 14123\n",
            "New sensible chunk: 243\n",
            "New sensible chunk: 14403\n",
            "New sensible chunk: 14405\n",
            "New sensible chunk: 14368\n",
            "New sensible chunk: 9703\n",
            "========== RESULTS ============\n",
            "============ Recall: 1.0\n",
            "============ Precision: 0.1687162098815588\n",
            "============ Accuracy: 0.1687162098815588\n",
            "============ F1 Score: 0.28872057810964563\n",
            "============ Relative error in total energy: 0.7178490238750633\n",
            "============ Mean absolute error(in Watts): 20.447456543004275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khSOeGHWujUc",
        "colab_type": "code",
        "outputId": "29b91163-d0aa-403a-efb4-23ccaa6f229d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "plt.plot(test_meterlist.power_series_all_data())#[0:100000])\n",
        "plt.plot(res_elec[meter_key].power_series_all_data())#[0:100000])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5b3e286588>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAD8CAYAAABkbJM/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVegEqMspJAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjXz1oEQvjEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.plot(test_meterlist.power_series_all_data()[0:1000000])\n",
        "res_elec[meter_key].power_series_all_data()[0:1000000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9IxOiiV3GXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}